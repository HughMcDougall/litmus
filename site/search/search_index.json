{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>HUGH MCDOUGALL 2024</p>"},{"location":"#litmus-documentation","title":"LITMUS Documentation","text":"<p>Lag Inference Through the Mixed Use of Samplers</p> <p>LITMUS is an in-progress program that uses modern statistical techniques, like nested sampling and stochastic variational inference, in combination with cutting edge programming tools like the just-in-time compilation framework <code>jax</code> and its bayesian modelling package <code>NumPyro</code>, to perform the messy task of lag recovery in AGN reverberation mapping.</p> <p></p> <p>This project is still very much in the early stages. If you have any questions, contact the author directly at hughmcdougallemail@gmail.com.</p>"},{"location":"GP_working/","title":"<code>litmus.GP_working</code>","text":"<p>gp_working.py</p> <p>Contains all interfacing with the tinyGP gaussian process modelling package</p> <p>Multi-band kernel adapated from:     \"Gaussian Process regression for astronomical time-series\"     Aigrain &amp; Foreman-Mackey, 2022:     https://arxiv.org/abs/2209.08940</p> <p>HM 2024</p>"},{"location":"GP_working/#litmus.gp_working.Multiband","title":"<code>Multiband</code>","text":"<p>               Bases: <code>Wrapper</code></p> <p>Multi-band GP kernel that knows how to scale GP to output amplitudes</p>"},{"location":"GP_working/#litmus.gp_working.Multiband.coord_to_sortable","title":"<code>coord_to_sortable(Y) -&gt; float</code>","text":"<p>Extracts the time value from the (time,band) coordinate so the GP can interpret the ordering of points in multiple bands</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def coord_to_sortable(self, Y) -&gt; float:\n    \"\"\"\n    Extracts the time value from the (time,band) coordinate so the GP can interpret the ordering of points\n    in multiple bands\n    \"\"\"\n    t, band = Y\n    return t\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.Multiband.observation_model","title":"<code>observation_model(Y) -&gt; float</code>","text":"<p>Scales the prediction for each band by their respective band amplitude in the predicted model</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def observation_model(self, Y) -&gt; float:\n    \"\"\"\n    Scales the prediction for each band by their respective band amplitude in the predicted model\n    \"\"\"\n    t, band = Y\n    return self.amplitudes[band] * self.kernel.observation_model(t)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.isiter","title":"<code>isiter(x: any) -&gt; bool</code>","text":"<p>Checks to see if an object is itterable</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter(x: any) -&gt; bool:\n    '''\n    Checks to see if an object is itterable\n    '''\n    if type(x) == dict:\n        return len(x[list(x.keys())[0]]) &gt; 1\n    try:\n        iter(x)\n    except:\n        return (False)\n    else:\n        return (True)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.isiter_dict","title":"<code>isiter_dict(DICT: dict) -&gt; bool</code>","text":"<p>like isiter but for a dictionary. Checks only the first element in DICT.keys</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter_dict(DICT: dict) -&gt; bool:\n    '''\n    like isiter but for a dictionary. Checks only the first element in DICT.keys\n    '''\n\n    key = list(DICT.keys())[0]\n    if isiter(DICT[key]):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_dim","title":"<code>dict_dim(DICT: dict) -&gt; (int, int)</code>","text":"<p>Checks the first element of a dictionary and returns its length</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_dim(DICT: dict) -&gt; (int, int):\n    '''\n    Checks the first element of a dictionary and returns its length\n    '''\n\n    if isiter_dict(DICT):\n        firstkey = list(DICT.keys())[0]\n        return (len(list(DICT.keys())), len(DICT[firstkey]))\n    else:\n        return (len(list(DICT.keys())), 1)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_pack","title":"<code>dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array</code>","text":"<p>Packs a dictionary into an array format</p> <p>Parameters:</p> Name Type Description Default <code>DICT</code> <code>dict</code> <p>the dict to unpack</p> required <code>keys</code> <p>the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial</p> <code>None</code> <code>recursive</code> <p>whether to recurse into arrays</p> <code>True</code> <code>H</code> <p>Matrix to scale parameters by</p> <code>None</code> <code>d0</code> <p>Value to offset by before packing</p> <code>{}</code> <p>Returns:</p> Type Description <code>array</code> <p>(nkeys x len_array) np.arrayobject  X = H (d-d0)</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array:\n    '''\n    Packs a dictionary into an array format\n    :param DICT: the dict to unpack\n    :param keys: the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial\n    :param recursive: whether to recurse into arrays\n    :param H: Matrix to scale parameters by\n    :param d0: Value to offset by before packing\n    :return: (nkeys x len_array) np.arrayobject\n\n    X = H (d-d0)\n    '''\n\n    nokeys = True if keys is None else 0\n    keys = keys if keys is not None else DICT.keys()\n\n    if d0 is {}: d0 = {key:0 for key in keys}\n\n    for key in keys:\n        if key in DICT.keys() and key not in d0.keys(): d0 |= {key: 0.0}\n\n    if recursive and type(list(DICT.values())[0]) == dict:\n        out = np.array(\n            [dict_pack(DICT[key] - d0[key], keys=keys if not nokeys else None, recursive=recursive) for key in keys])\n    else:\n        if isiter(DICT[list(keys)[0]]):\n            out = np.array([[DICT[key][i] - d0[key] for i in range(dict_dim(DICT)[1])] for key in keys])\n        else:\n            out = np.array([DICT[key] - d0[key] for key in keys])\n\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_unpack","title":"<code>dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array</code>","text":"<p>Unpacks an array into a dict</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Array to unpack</p> required <code>keys</code> <code>[str]</code> <p>keys to unpack with</p> required <p>Returns:</p> Type Description <code>array</code> <p>Hinv(X) + x0</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array:\n    \"\"\"\n    Unpacks an array into a dict\n    :param X: Array to unpack\n    :param keys: keys to unpack with\n    :return:\n\n    Hinv(X) + x0\n    \"\"\"\n    if Hinv is not None: assert Hinv.shape[0] == len(keys), \"Size of H must be equal to number of keys in dict_unpack\"\n\n    if recursive and isiter(X[0]):\n        out = {key: dict_unpack(X[i], keys, recursive) for i, key in enumerate(list(keys))}\n    else:\n        X = X.copy()\n        if Hinv is not None:\n            X = np.dot(Hinv, X)\n        if x0 is not None:\n            X += x0\n        out = {key: X[i] for i, key in enumerate(list(keys))}\n\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_sortby","title":"<code>dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict</code>","text":"<p>Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both. Else, append un-sorted entries to end</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict:\n    \"\"\"\n    Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both.\n    Else, append un-sorted entries to end\n    \"\"\"\n    out = {key: A[key] for key in B if key in A}\n    if not match_only:\n        out |= {key: A[key] for key in A if key not in B}\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_extend","title":"<code>dict_extend(A: dict, B: dict = None) -&gt; dict</code>","text":"<p>Extends all single-length entries of a dict to match the length of a non-singular element</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>dict</code> <p>Dictionary whose elements are to be extended</p> required <code>B</code> <code>dict</code> <p>(optional) the array to extend by, equivalent to dict_extend(A|B)</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_extend(A: dict, B: dict = None) -&gt; dict:\n    '''\n    Extends all single-length entries of a dict to match the length of a non-singular element\n    :param A: Dictionary whose elements are to be extended\n    :param B: (optional) the array to extend by, equivalent to dict_extend(A|B)\n    :return:\n    '''\n\n    out = A.copy()\n    if B is not None: out |= B\n\n    to_extend = [key for key in out if not isiter(out[key])]\n    to_leave = [key for key in out if isiter(out[key])]\n\n    if len(to_extend) == 0: return out\n    if len(to_leave) == 0: return out\n\n    N = len(out[to_leave[0]])\n    for key in to_leave[1:]:\n        assert len(out[key]) == N, \"Tried to dict_extend() a dictionary with inhomogeneous lengths\"\n\n    for key in to_extend:\n        out[key] = np.array([A[key]] * N)\n\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_combine","title":"<code>dict_combine(X: [dict]) -&gt; {str: [float]}</code>","text":"<p>Combines an array, list etc of dictionary into a dictionary of arrays</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_combine(X: [dict]) -&gt; {str: [float]}:\n    '''\n    Combines an array, list etc of dictionary into a dictionary of arrays\n    '''\n\n    N = len(X)\n    keys = X[0].keys()\n\n    out = {key: np.zeros(N) for key in keys}\n    for n in range(N):\n        for key in keys:\n            out[key][n] = X[n][key]\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.dict_divide","title":"<code>dict_divide(X: dict) -&gt; [dict]</code>","text":"<p>Splits dict of arrays into array of dicts</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_divide(X: dict) -&gt; [dict]:\n    '''\n    Splits dict of arrays into array of dicts\n    '''\n\n    keys = list(X.keys())\n    N = len(X[keys[0]])\n\n    out = [{key: X[key][i] for key in X} for i in range(N)]\n\n    return (out)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.pack_function","title":"<code>pack_function(func, packed_keys: [str], fixed_values: dict = {}, invert: bool = False, jit: bool = False, H: np.array = None, d0: dict = {})</code>","text":"<p>Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly Takes a function f(D:dict, arg, kwargs) and returns f(X, D2, args, **kwargs), D2 is all elements of D not listed in 'packed_keys' or fixed_values.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>Function to be unpacked</p> required <code>packed_keys</code> <code>[str]</code> <p>Keys in 'D' to be packed in an array</p> required <code>fixed_values</code> <code>dict</code> <p>Elements of 'D' to be fixed</p> <code>{}</code> <code>invert</code> <code>bool</code> <p>If true, will 'flip' the function upside down</p> <code>False</code> <code>jit</code> <code>bool</code> <p>If true, will 'jit' the function</p> <code>False</code> <code>H</code> <code>array</code> <p>(optional) scaling matrix to reparameterize H with</p> <code>None</code> <code>x0</code> <p>(optional) If given, will center the reparameterized  function at x0</p> required Source code in <code>litmus/_utils.py</code> <pre><code>def pack_function(func, packed_keys: ['str'], fixed_values: dict = {}, invert: bool = False, jit: bool = False,\n                  H: np.array = None, d0: dict = {}):\n    '''\n    Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly\n    Takes a function f(D:dict, *arg, **kwargs) and returns f(X, D2, *args, **kwargs), D2 is all elements of D not\n    listed in 'packed_keys' or fixed_values.\n\n    :param func: Function to be unpacked\n    :param packed_keys: Keys in 'D' to be packed in an array\n    :param fixed_values: Elements of 'D' to be fixed\n    :param invert:  If true, will 'flip' the function upside down\n    :param jit: If true, will 'jit' the function\n    :param H: (optional) scaling matrix to reparameterize H with\n    :param x0: (optional) If given, will center the reparameterized  function at x0\n    '''\n\n    if H is not None:\n        assert H.shape[0] == len(packed_keys), \"Scaling matrix H must be same length as packed_keys\"\n    else:\n        H = jnp.eye(len(packed_keys))\n    d0 = {key: 0.0 for key in packed_keys} | d0\n    x0 = dict_pack(d0, packed_keys)\n\n    # --------\n\n    sign = -1 if invert else 1\n\n    # --------\n    def new_func(X, unpacked_params={}, *args, **kwargs):\n        X = jnp.dot(H, X - x0)\n        packed_dict = {key: x for key, x in zip(packed_keys, X)}\n        packed_dict |= unpacked_params\n        packed_dict |= fixed_values\n\n        out = func(packed_dict, *args, **kwargs)\n        return (sign * out)\n\n    # --------\n    if jit: new_func = jax.jit(new_func)\n\n    return (new_func)\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.mean_func","title":"<code>mean_func(means, Y) -&gt; ArrayN</code>","text":"<p>DEPRECATED - means are subtracted in the model now Utitlity function to take array of constants and return as gp-friendly functions</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def mean_func(means, Y) -&gt; ArrayN:\n    \"\"\"\n    DEPRECATED - means are subtracted in the model now\n    Utitlity function to take array of constants and return as gp-friendly functions\n\n    \"\"\"\n    t, band = Y\n    return (means[band])\n</code></pre>"},{"location":"GP_working/#litmus.gp_working.build_gp","title":"<code>build_gp(T: ArrayN, Y: ArrayN, diag: ArrayNxN, bands: ArrayN, tau: float, amps: tuple[float, float], means: tuple[float, float], basekernel=tinygp.kernels.quasisep.Exp) -&gt; GaussianProcess</code>","text":"<p>Builds a tinygp two-band kernel for predictions</p> <p>Parameters:</p> Name Type Description Default <code>T</code> <code>ArrayN</code> <p>Time values for the GP</p> required <code>Y</code> <code>ArrayN</code> <p>Y values for the GP (No effect)</p> required <code>diag</code> <code>ArrayNxN</code> <p>Variance matrix (square uncertainties) of the GP</p> required <code>bands</code> <code>ArrayN</code> <p>The bands that the different entries in the time series correspond to</p> required <code>tau</code> <code>float</code> <p>Timescale of the GP</p> required <code>amps</code> <code>tuple[float, float]</code> <p>Amplitudes of the GP</p> required <code>means</code> <code>tuple[float, float]</code> required <code>basekernel</code> <code>Exp</code> Source code in <code>litmus/gp_working.py</code> <pre><code>def build_gp(T: ArrayN, Y: ArrayN, diag: ArrayNxN, bands: ArrayN, tau: float,\n             amps: tuple[float, float], means: tuple[float, float],\n             basekernel=tinygp.kernels.quasisep.Exp) -&gt; GaussianProcess:\n    \"\"\"\n    Builds a tinygp two-band kernel for predictions\n\n    :parameter T: Time values for the GP\n    :parameter Y: Y values for the GP (No effect)\n    :parameter diag: Variance matrix (square uncertainties) of the GP\n    :parameter bands: The bands that the different entries in the time series correspond to\n    :parameter tau: Timescale of the GP\n    :parameter amps: Amplitudes of the GP\n    :parameter means:\n    :parameter basekernel:\n    \"\"\"\n\n    # Create GP kernel with Multiband\n    multi_kernel = Multiband(\n        kernel=basekernel(scale=tau),\n        amplitudes=amps,\n    )\n\n    # Mean functions for offsetting signals\n    meanf = lambda X: mean_func(means, X)\n\n    # Construct GP object and return\n    gp = GaussianProcess(\n        multi_kernel,\n        (T, bands),\n        diag=diag,\n        mean=meanf\n    )\n    return (gp)\n</code></pre>"},{"location":"_utils/","title":"<code>litmus._utils</code>","text":"<p>utils.py Handy internal utilities for brevity and convenience. Nothing in here is accesible in the public _init file</p>"},{"location":"_utils/#litmus._utils.isiter","title":"<code>isiter(x: any) -&gt; bool</code>","text":"<p>Checks to see if an object is itterable</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter(x: any) -&gt; bool:\n    '''\n    Checks to see if an object is itterable\n    '''\n    if type(x) == dict:\n        return len(x[list(x.keys())[0]]) &gt; 1\n    try:\n        iter(x)\n    except:\n        return (False)\n    else:\n        return (True)\n</code></pre>"},{"location":"_utils/#litmus._utils.isiter_dict","title":"<code>isiter_dict(DICT: dict) -&gt; bool</code>","text":"<p>like isiter but for a dictionary. Checks only the first element in DICT.keys</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter_dict(DICT: dict) -&gt; bool:\n    '''\n    like isiter but for a dictionary. Checks only the first element in DICT.keys\n    '''\n\n    key = list(DICT.keys())[0]\n    if isiter(DICT[key]):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_dim","title":"<code>dict_dim(DICT: dict) -&gt; (int, int)</code>","text":"<p>Checks the first element of a dictionary and returns its length</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_dim(DICT: dict) -&gt; (int, int):\n    '''\n    Checks the first element of a dictionary and returns its length\n    '''\n\n    if isiter_dict(DICT):\n        firstkey = list(DICT.keys())[0]\n        return (len(list(DICT.keys())), len(DICT[firstkey]))\n    else:\n        return (len(list(DICT.keys())), 1)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_pack","title":"<code>dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array</code>","text":"<p>Packs a dictionary into an array format</p> <p>Parameters:</p> Name Type Description Default <code>DICT</code> <code>dict</code> <p>the dict to unpack</p> required <code>keys</code> <p>the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial</p> <code>None</code> <code>recursive</code> <p>whether to recurse into arrays</p> <code>True</code> <code>H</code> <p>Matrix to scale parameters by</p> <code>None</code> <code>d0</code> <p>Value to offset by before packing</p> <code>{}</code> <p>Returns:</p> Type Description <code>array</code> <p>(nkeys x len_array) np.arrayobject  X = H (d-d0)</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array:\n    '''\n    Packs a dictionary into an array format\n    :param DICT: the dict to unpack\n    :param keys: the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial\n    :param recursive: whether to recurse into arrays\n    :param H: Matrix to scale parameters by\n    :param d0: Value to offset by before packing\n    :return: (nkeys x len_array) np.arrayobject\n\n    X = H (d-d0)\n    '''\n\n    nokeys = True if keys is None else 0\n    keys = keys if keys is not None else DICT.keys()\n\n    if d0 is {}: d0 = {key:0 for key in keys}\n\n    for key in keys:\n        if key in DICT.keys() and key not in d0.keys(): d0 |= {key: 0.0}\n\n    if recursive and type(list(DICT.values())[0]) == dict:\n        out = np.array(\n            [dict_pack(DICT[key] - d0[key], keys=keys if not nokeys else None, recursive=recursive) for key in keys])\n    else:\n        if isiter(DICT[list(keys)[0]]):\n            out = np.array([[DICT[key][i] - d0[key] for i in range(dict_dim(DICT)[1])] for key in keys])\n        else:\n            out = np.array([DICT[key] - d0[key] for key in keys])\n\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_unpack","title":"<code>dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array</code>","text":"<p>Unpacks an array into a dict</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Array to unpack</p> required <code>keys</code> <code>[str]</code> <p>keys to unpack with</p> required <p>Returns:</p> Type Description <code>array</code> <p>Hinv(X) + x0</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array:\n    \"\"\"\n    Unpacks an array into a dict\n    :param X: Array to unpack\n    :param keys: keys to unpack with\n    :return:\n\n    Hinv(X) + x0\n    \"\"\"\n    if Hinv is not None: assert Hinv.shape[0] == len(keys), \"Size of H must be equal to number of keys in dict_unpack\"\n\n    if recursive and isiter(X[0]):\n        out = {key: dict_unpack(X[i], keys, recursive) for i, key in enumerate(list(keys))}\n    else:\n        X = X.copy()\n        if Hinv is not None:\n            X = np.dot(Hinv, X)\n        if x0 is not None:\n            X += x0\n        out = {key: X[i] for i, key in enumerate(list(keys))}\n\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_sortby","title":"<code>dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict</code>","text":"<p>Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both. Else, append un-sorted entries to end</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict:\n    \"\"\"\n    Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both.\n    Else, append un-sorted entries to end\n    \"\"\"\n    out = {key: A[key] for key in B if key in A}\n    if not match_only:\n        out |= {key: A[key] for key in A if key not in B}\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_extend","title":"<code>dict_extend(A: dict, B: dict = None) -&gt; dict</code>","text":"<p>Extends all single-length entries of a dict to match the length of a non-singular element</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>dict</code> <p>Dictionary whose elements are to be extended</p> required <code>B</code> <code>dict</code> <p>(optional) the array to extend by, equivalent to dict_extend(A|B)</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_extend(A: dict, B: dict = None) -&gt; dict:\n    '''\n    Extends all single-length entries of a dict to match the length of a non-singular element\n    :param A: Dictionary whose elements are to be extended\n    :param B: (optional) the array to extend by, equivalent to dict_extend(A|B)\n    :return:\n    '''\n\n    out = A.copy()\n    if B is not None: out |= B\n\n    to_extend = [key for key in out if not isiter(out[key])]\n    to_leave = [key for key in out if isiter(out[key])]\n\n    if len(to_extend) == 0: return out\n    if len(to_leave) == 0: return out\n\n    N = len(out[to_leave[0]])\n    for key in to_leave[1:]:\n        assert len(out[key]) == N, \"Tried to dict_extend() a dictionary with inhomogeneous lengths\"\n\n    for key in to_extend:\n        out[key] = np.array([A[key]] * N)\n\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_combine","title":"<code>dict_combine(X: [dict]) -&gt; {str: [float]}</code>","text":"<p>Combines an array, list etc of dictionary into a dictionary of arrays</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_combine(X: [dict]) -&gt; {str: [float]}:\n    '''\n    Combines an array, list etc of dictionary into a dictionary of arrays\n    '''\n\n    N = len(X)\n    keys = X[0].keys()\n\n    out = {key: np.zeros(N) for key in keys}\n    for n in range(N):\n        for key in keys:\n            out[key][n] = X[n][key]\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.dict_divide","title":"<code>dict_divide(X: dict) -&gt; [dict]</code>","text":"<p>Splits dict of arrays into array of dicts</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_divide(X: dict) -&gt; [dict]:\n    '''\n    Splits dict of arrays into array of dicts\n    '''\n\n    keys = list(X.keys())\n    N = len(X[keys[0]])\n\n    out = [{key: X[key][i] for key in X} for i in range(N)]\n\n    return (out)\n</code></pre>"},{"location":"_utils/#litmus._utils.pack_function","title":"<code>pack_function(func, packed_keys: [str], fixed_values: dict = {}, invert: bool = False, jit: bool = False, H: np.array = None, d0: dict = {})</code>","text":"<p>Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly Takes a function f(D:dict, arg, kwargs) and returns f(X, D2, args, **kwargs), D2 is all elements of D not listed in 'packed_keys' or fixed_values.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>Function to be unpacked</p> required <code>packed_keys</code> <code>[str]</code> <p>Keys in 'D' to be packed in an array</p> required <code>fixed_values</code> <code>dict</code> <p>Elements of 'D' to be fixed</p> <code>{}</code> <code>invert</code> <code>bool</code> <p>If true, will 'flip' the function upside down</p> <code>False</code> <code>jit</code> <code>bool</code> <p>If true, will 'jit' the function</p> <code>False</code> <code>H</code> <code>array</code> <p>(optional) scaling matrix to reparameterize H with</p> <code>None</code> <code>x0</code> <p>(optional) If given, will center the reparameterized  function at x0</p> required Source code in <code>litmus/_utils.py</code> <pre><code>def pack_function(func, packed_keys: ['str'], fixed_values: dict = {}, invert: bool = False, jit: bool = False,\n                  H: np.array = None, d0: dict = {}):\n    '''\n    Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly\n    Takes a function f(D:dict, *arg, **kwargs) and returns f(X, D2, *args, **kwargs), D2 is all elements of D not\n    listed in 'packed_keys' or fixed_values.\n\n    :param func: Function to be unpacked\n    :param packed_keys: Keys in 'D' to be packed in an array\n    :param fixed_values: Elements of 'D' to be fixed\n    :param invert:  If true, will 'flip' the function upside down\n    :param jit: If true, will 'jit' the function\n    :param H: (optional) scaling matrix to reparameterize H with\n    :param x0: (optional) If given, will center the reparameterized  function at x0\n    '''\n\n    if H is not None:\n        assert H.shape[0] == len(packed_keys), \"Scaling matrix H must be same length as packed_keys\"\n    else:\n        H = jnp.eye(len(packed_keys))\n    d0 = {key: 0.0 for key in packed_keys} | d0\n    x0 = dict_pack(d0, packed_keys)\n\n    # --------\n\n    sign = -1 if invert else 1\n\n    # --------\n    def new_func(X, unpacked_params={}, *args, **kwargs):\n        X = jnp.dot(H, X - x0)\n        packed_dict = {key: x for key, x in zip(packed_keys, X)}\n        packed_dict |= unpacked_params\n        packed_dict |= fixed_values\n\n        out = func(packed_dict, *args, **kwargs)\n        return (sign * out)\n\n    # --------\n    if jit: new_func = jax.jit(new_func)\n\n    return (new_func)\n</code></pre>"},{"location":"fitting_methods/","title":"<code>litmus.fitting_methods</code>","text":"<p>Contains fitting procedures to be executed by the litmus class object</p> <p>HM 24</p>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure","title":"<code>fitting_procedure(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=True, **fit_params)</code>","text":"<p>               Bases: <code>logger</code></p> <p>Generic class for lag fitting procedures. Contains parent methods for setting properties</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout,\n             err_stream=sys.stderr,\n             verbose=True,\n             debug=True,\n             **fit_params):\n\n    logger.__init__(self,\n                    out_stream=out_stream,\n                    err_stream=err_stream,\n                    verbose=verbose,\n                    debug=debug,\n                    )\n\n    if not hasattr(self, \"_default_params\"):\n        self._default_params = {}\n\n    self.stat_model = stat_model\n\n    self.name = \"Base Fitting Procedure\"\n\n    self.is_ready = False\n    self.has_prefit = False\n    self.has_run = False\n\n    self.fitting_params = {} | self._default_params\n    self.set_config(**(self._default_params | fit_params))\n\n    self.seed = _utils.randint() if \"seed\" not in fit_params.keys() else fit_params['seed']\n    self._tempseed = self.seed\n    self._data = None\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.reset","title":"<code>reset() -&gt; None</code>","text":"<p>Clears all memory and resets params to defaults</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Clears all memory and resets params to defaults\n    \"\"\"\n    self.set_config(**self._default_params)\n\n    self.has_run, self.is_ready = False, False\n\n    return\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.set_config","title":"<code>set_config(**fit_params) -&gt; None</code>","text":"<p>Configure fitting parameters for fitting_method() object Accepts any parameters present with a name in fitting_method.fitting_params Unlisted parameters will be ignored.</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def set_config(self, **fit_params) -&gt; None:\n    \"\"\"\n    Configure fitting parameters for fitting_method() object\n    Accepts any parameters present with a name in fitting_method.fitting_params\n    Unlisted parameters will be ignored.\n    \"\"\"\n\n    if self.debug: print(\"Doing config with keys\", fit_params.keys())\n\n    badkeys = [key for key in fit_params.keys() if key not in self._default_params.keys()]\n\n    for key, val in zip(fit_params.keys(), fit_params.values()):\n        if key in badkeys: continue\n\n        # If something's changed, flag as having not run\n        currval = self.__getattribute__(key)\n        if self.has_run and val != currval: self.has_run = False\n\n        self.__setattr__(key, val)\n        # self.fitting_params |= {key: val}\n        if self.debug: print(\"\\t set attr\", key, file=self.out_stream)\n\n    if len(badkeys) &gt; 0:\n        self.msg_err(\"Tried to configure bad keys:\", *badkeys, delim='\\t')\n    return\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.readyup","title":"<code>readyup() -&gt; None</code>","text":"<p>Performs pre-fit preparation calcs. Should only be called if not self.is_ready()</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def readyup(self) -&gt; None:\n    \"\"\"\n    Performs pre-fit preparation calcs. Should only be called if not self.is_ready()\n    \"\"\"\n    self.is_ready = True\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.prefit","title":"<code>prefit(lc_1: lightcurve, lc_2: lightcurve, seed: int = None) -&gt; None</code>","text":"<p>Fit lags</p> <p>Parameters:</p> Name Type Description Default <code>lc_1</code> <code>lightcurve</code> <p>Lightcurve 1 (Main)</p> required <code>lc_2</code> <code>lightcurve</code> <p>Lightcurve 2 (Response)</p> required <code>seed</code> <code>int</code> <p>A random seed for feeding to the fitting process. If none, will select randomly</p> <code>None</code> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def prefit(self, lc_1: lightcurve, lc_2: lightcurve, seed: int = None) -&gt; None:\n    \"\"\"\n    Fit lags\n    :param lc_1: Lightcurve 1 (Main)\n    :param lc_2: Lightcurve 2 (Response)\n    :param seed: A random seed for feeding to the fitting process. If none, will select randomly\n    \"\"\"\n\n    self.has_prefit = True\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.fit","title":"<code>fit(lc_1: lightcurve, lc_2: lightcurve, seed: int = None) -&gt; None</code>","text":"<p>Fit lags</p> <p>Parameters:</p> Name Type Description Default <code>lc_1</code> <code>lightcurve</code> <p>Lightcurve 1 (Main)</p> required <code>lc_2</code> <code>lightcurve</code> <p>Lightcurve 2 (Response)</p> required <code>seed</code> <code>int</code> <p>A random seed for feeding to the fitting process. If none, will select randomly</p> <code>None</code> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def fit(self, lc_1: lightcurve, lc_2: lightcurve, seed: int = None) -&gt; None:\n    \"\"\"\n    Fit lags\n    :param lc_1: Lightcurve 1 (Main)\n    :param lc_2: Lightcurve 2 (Response)\n    :param seed: A random seed for feeding to the fitting process. If none, will select randomly\n    \"\"\"\n\n    # Sanity checks inherited by all subclasses\n    if not self.is_ready: self.readyup()\n    if isinstance(seed, int):\n        self._tempseed = seed\n        self._tempseed = _utils.randint()\n        self._tempseed = _utils.randint()\n    seed = self._tempseed\n\n    data = self.stat_model.lc_to_data(lc_1, lc_2)\n    self._data = data\n\n    # An error message raised if this fitting procedure doesn't have .fit()\n    if self.__class__.fit == fitting_procedure.fit:\n        self.msg_err(\"Fitting \\\"%s\\\" method does not have method .fit() implemented\" % self.name)\n\n    return\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.get_samples","title":"<code>get_samples(N: int = None, seed: int = None, importance_sampling: bool = False) -&gt; {str: [float]}</code>","text":"<p>Returns MCMC-like posterior samples</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Number of samples to return. If None, return all</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for any stochastic elements</p> <code>None</code> <code>importance_sampling</code> <code>bool</code> <p>If true, will weight the results by</p> <code>False</code> <p>Returns:</p> Type Description <code>{str: [float]}</code> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_samples(self, N: int = None, seed: int = None, importance_sampling: bool = False) -&gt; {str: [float]}:\n    '''\n    Returns MCMC-like posterior samples\n    :param N: Number of samples to return. If None, return all\n    :param seed: Random seed for any stochastic elements\n    :param importance_sampling: If true, will weight the results by\n    :return:\n    '''\n\n    if not self.is_ready: self.readyup()\n    if isinstance(seed, int):\n        self._tempseed = seed\n        self._tempseed = _utils.randint()\n    seed = self._tempseed\n\n    if self.__class__.fit == fitting_procedure.fit:\n        self.msg_err(\"Fitting \\\"%s\\\" method does not have method .get_samples() implemented\" % self.name)\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.get_evidence","title":"<code>get_evidence(seed: int = None, return_type='linear') -&gt; [float, float, float]</code>","text":"<p>Returns the estimated evidence for the fit model. if return_type = 'linear', returns as array-like [Z,-dZ-,dZ+] if return_type = 'log', returns as array-like [logZ,-dlogZ-,dlogZ+]</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_evidence(self, seed: int = None, return_type='linear') -&gt; [float, float, float]:\n    \"\"\"\n    Returns the estimated evidence for the fit model.\n    if return_type = 'linear', returns as array-like [Z,-dZ-,dZ+]\n    if return_type = 'log', returns as array-like [logZ,-dlogZ-,dlogZ+]\n    \"\"\"\n\n    assert return_type in ['linear', 'log'], \"Return type must be 'linear' or 'log'\"\n\n    if not self.is_ready: self.readyup()\n    if not self.has_run: self.msg_err(\"Warning! Tried to call get_evidence without running first!\")\n\n    if isinstance(seed, int):\n        self._tempseed = seed\n        self._tempseed = _utils.randint()\n    seed = self._tempseed\n\n    if self.__class__.get_evidence == fitting_procedure.get_evidence:\n        self.msg_err(\"Fitting \\\"%s\\\" method does not have method .get_evidence() implemented\" % self.name)\n        return np.array([0.0, 0.0, 0.0])\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.get_information","title":"<code>get_information(seed: int = None) -&gt; [float, float, float]</code>","text":"<p>Returns an estimate of the information (KL divergence relative to prior). Returns as array-like [I,dI-,dI+]</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_information(self, seed: int = None) -&gt; [float, float, float]:\n    \"\"\"\n    Returns an estimate of the information (KL divergence relative to prior). Returns as array-like [I,dI-,dI+]\n    \"\"\"\n\n    if not self.is_ready: self.readyup()\n    if isinstance(seed, int):\n        self._tempseed = seed\n        self._tempseed = _utils.randint()\n    seed = self._tempseed\n\n    if self.__class__.get_information == fitting_procedure.get_information:\n        self.msg_err(\"Fitting \\\"%s\\\" method does not have method .get_information() implemented\" % self.name)\n\n        return np.array([0.0, 0.0, 0.0])\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.fitting_procedure.get_peaks","title":"<code>get_peaks(seed=None)</code>","text":"<p>Returns the maximum posterior position in parameter space</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_peaks(self, seed=None):\n    \"\"\"\n    Returns the maximum posterior position in parameter space\n    \"\"\"\n\n    if not self.is_ready: self.readyup()\n    if isinstance(seed, int):\n        self._tempseed = seed\n        self._tempseed = _utils.randint()\n    seed = self._tempseed\n\n    if self.__class__.get_peaks == fitting_procedure.get_peaks:\n        self.msg_err(\"Fitting \\\"%s\\\" method does not have method .get_peaks() implemented\" % self.name)\n\n        return {}, np.array([])\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.ICCF","title":"<code>ICCF(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>fitting_procedure</code></p> <p>Fit lags using interpolated cross correlation function in the style of pyCCF. Note that this is not a Bayesian fitter and gives only approximate measures of the lag todo     - Add p value, false positive and evidence estimates (?)</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n\n    self._default_params |= {\n        'Nboot': 512,\n        'Nterp': 2014,\n        'Nlags': 512,\n    }\n\n    super().__init__(**args_in)\n\n    self.name = \"ICCF Fitting Procedure\"\n    self.lags = np.zeros(self.Nterp)\n\n    # -----------------------------------\n    self.samples = np.zeros(self.Nboot)\n    self.correl_curve = np.zeros(self.Nterp)\n    self.lag_mean = 0.0\n    self.lag_err = 0.0\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.prior_sampling","title":"<code>prior_sampling(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>fitting_procedure</code></p> <p>Randomly samples from the prior and weights with importance sampling. The crudest available sampler. For test purposes only, not suggested for actual use.</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n\n    # ------------------------------------\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n    self._default_params |= {\n        'Nsamples': 4096\n    }\n\n    super().__init__(**args_in)\n    # ------------------------------------\n\n    self.name = \"Prior Sampling Fitting Procedure\"\n\n    self.samples = np.zeros(self.Nsamples)\n    self.log_likes = np.zeros(self.Nsamples)\n    self.weights = np.zeros(self.Nsamples)\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.nested_sampling","title":"<code>nested_sampling(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>fitting_procedure</code></p> <p>Fits the Bayesian model with Nested Sampling by using JAXNS. Highly accurate evidence / posterior distributions, but can be slow for models with more than a few parameters. Use only if hessian_scan and SVI_scan fail.</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n    self._default_params |= {\n        'num_live_points': 500,\n        'max_samples': 10_000,\n        'num_parallel_samplers': 1,\n        'evidence_uncert': 1E-3,\n        'live_evidence_frac': np.log(1 + 1e-3),\n    }\n\n    super().__init__(**args_in)\n\n    self.name = \"Nested Sampling Fitting Procedure\"\n\n    self.sampler = None\n\n    self._jaxnsmodel = None\n    self._jaxnsresults = None\n    self._jaxnstermination = None\n    self._jaxnsresults = None\n\n    self.logevidence = jnp.zeros(3)\n    self.priorvolume = 0.0\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.nested_sampling.get_evidence","title":"<code>get_evidence(seed: int = None, return_type='linear') -&gt; [float, float, float]</code>","text":"<p>Returns the -1, 0 and +1 sigma values for model evidence from nested sampling. This represents an estimate of numerical uncertainty</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_evidence(self, seed: int = None, return_type='linear') -&gt; [float, float, float]:\n    '''\n    Returns the -1, 0 and +1 sigma values for model evidence from nested sampling.\n    This represents an estimate of numerical uncertainty\n    '''\n\n    if seed is None: seed = _utils.randint()\n\n    l, l_e = self._jaxnsresults.log_Z_mean, self._jaxnsresults.log_Z_uncert\n\n    if return_type == 'linear':\n\n        out = np.exp([\n            l,\n            l - l_e,\n            l + l_e\n        ])\n\n        out -= np.array([0, out[0], out[0]])\n    elif return_type == 'log':\n        out = np.array([l, -l_e, l_e])\n\n    return out\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.nested_sampling.get_information","title":"<code>get_information(seed: int = None) -&gt; [float, float, float]</code>","text":"<p>Use the Nested Sampling shells to estimate the model information relative to prior</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def get_information(self, seed: int = None) -&gt; [float, float, float]:\n    '''\n    Use the Nested Sampling shells to estimate the model information relative to prior\n    '''\n    # todo - this is outmoded\n\n    if seed is None: seed = _utils.randint()\n\n    NS = self.sampler\n    samples, logweights = self._jaxnsresults.samples, self._jaxnsresults.log_dp_mean\n\n    weights = np.exp(logweights)\n    weights /= weights.sum()\n\n    log_density = self._jaxnsresults.log_posterior_density\n    prior_values = self.stat_model.log_prior(samples)\n\n    info = np.sum((log_density - prior_values) * weights)\n\n    partial_info = np.random.choice((log_density - prior_values), len(log_density), p=weights)\n    uncert = partial_info.std() / np.sqrt(len(log_density))\n\n    return (np.array(info, uncert, uncert))\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.hessian_scan","title":"<code>hessian_scan(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>fitting_procedure</code></p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n\n    self._default_params |= {\n        'Nlags': 64,\n        'opt_tol': 1E-2,\n        'opt_tol_init': 1E-4,\n        'step_size': 0.001,\n        'constrained_domain': False,\n        'max_opt_eval': 1_000,\n        'max_opt_eval_init': 5_000,\n        'LL_threshold': 100.0,\n        'init_samples': 5_000,\n        'grid_bunching': 0.5,\n        'grid_depth': None,\n        'grid_Nterp': None,\n        'grid_relaxation': 0.1,  # deprecated, remove\n        'grid_firstdepth': 2.0,\n        'reverse': True,\n        'split_lags': True,\n        'optimizer_args_init': {},\n        'optimizer_args': {},\n        'seed_params': {},\n        'precondition': 'diag',\n        'interp_scale': 'log',\n    }\n\n    self._allowable_interpscales = ['linear', 'log']\n\n    super().__init__(**args_in)\n\n    # -----------------------------------\n\n    self.name = \"Hessian Scan Fitting Procedure\"\n\n    self.lags: [float] = np.zeros(self.Nlags)\n    self.converged: np.ndarray[bool] = np.zeros_like(self.lags, dtype=bool)\n\n    self.scan_peaks: dict = {None}\n    self.log_evidences: list = None\n    self.log_evidences_uncert: list = None\n\n    self.diagnostic_hessians: list = None\n    self.diagnostic_densities: list = None\n    self.diagnostic_grads: list = None\n    self.diagnostic_ints: list = None\n    self.diagnostic_tgrads: list = None\n\n    self.params_toscan = self.stat_model.free_params()\n    if 'lag' in self.params_toscan: self.params_toscan.remove('lag')\n\n    self.precon_matrix: np.ndarray[np.float64] = np.eye(len(self.params_toscan), dtype=np.float64)\n    self.solver: jaxopt.BFGS = None\n\n    self.estmap_params = {}\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.hessian_scan.estimate_MAP","title":"<code>estimate_MAP(lc_1: lightcurve, lc_2: lightcurve, seed: int = None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>lc_1</code> <code>lightcurve</code> required <code>lc_2</code> <code>lightcurve</code> required <code>seed</code> <code>int</code> <code>None</code> <p>Returns:</p> Type Description Source code in <code>litmus/fitting_methods.py</code> <pre><code>def estimate_MAP(self, lc_1: lightcurve, lc_2: lightcurve, seed: int = None):\n    '''\n    :param lc_1:\n    :param lc_2:\n    :param seed:\n    :return:\n    '''\n\n    data = self.stat_model.lc_to_data(lc_1, lc_2)\n\n    # ----------------------------------\n    # Find seed for optimization if not supplies\n    if self.stat_model.free_params() != self.seed_params.keys():\n        seed_params, ll_start = self.stat_model.find_seed(data, guesses=self.init_samples, fixed=self.seed_params)\n\n        self.msg_run(\"Beginning scan at constrained-space position:\")\n        for it in seed_params.items():\n            self.msg_run('\\t %s: \\t %.2f' % (it[0], it[1]))\n        self.msg_run(\n            \"Log-Density for this is: %.2f\" % ll_start)\n\n    else:\n        seed_params = self.seed_params\n        ll_start = self.stat_model.log_density(seed_params,\n                                               data=data\n                                               )\n\n    # ----------------------------------\n    # SCANNING FOR OPT\n\n    self.msg_run(\"Moving non-lag params to new location...\")\n    estmap_params = self.stat_model.scan(start_params=seed_params,\n                                         optim_params=[key for key in self.stat_model.free_params() if\n                                                       key != 'lag'],\n                                         data=data,\n                                         optim_kwargs=self.optimizer_args_init,\n                                         precondition=self.precondition\n                                         )\n    ll_firstscan = self.stat_model.log_density(estmap_params, data)\n    if 'lag' in self.stat_model.free_params():\n        self.msg_run(\"Optimizer settled at new fit:\")\n        for it in estmap_params.items():\n            self.msg_run('\\t %s: \\t %.2f' % (it[0], it[1]))\n        self.msg_run(\n            \"Log-Density for this is: %.2f\" % ll_firstscan\n        )\n\n        self.msg_run(\"Finding a good lag...\")\n        test_lags = self.stat_model.prior_sample(self.init_samples)['lag']\n        test_samples = _utils.dict_extend(estmap_params, {'lag': test_lags})\n        ll_test = self.stat_model.log_density(test_samples, data)\n        bestlag = test_lags[ll_test.argmax()]\n\n        self.msg_run(\"Grid finds good lag at %.2f:\" % bestlag)\n        self.msg_run(\n            \"Log-Density for this is: %.2f\" % ll_test.max()\n        )\n\n        if ll_test.max() &gt; ll_firstscan:\n            bestlag = bestlag\n        else:\n            bestlag = estmap_params['lag']\n\n        estmap_params = self.stat_model.scan(start_params=estmap_params | {'lag': bestlag},\n                                             optim_params=['lag'],\n                                             data=data,\n                                             optim_kwargs=self.optimizer_args_init,\n                                             precondition=self.precondition\n                                             )\n\n        self.msg_run(\"Lag-only opt settled at new lag %.2f...\" % estmap_params['lag'])\n\n    ll_end = self.stat_model.log_density(estmap_params,\n                                         data=data\n                                         )\n\n    # ----------------------------------\n    # CHECKING OUTPUTS\n\n    self.msg_run(\"Optimizer settled at new fit:\")\n    for it in estmap_params.items():\n        self.msg_run('\\t %s: \\t %.2f' % (it[0], it[1]))\n    self.msg_run(\n        \"Log-Density for this is: %.2f\" % ll_end\n    )\n\n    # ----------------------------------\n    # CHECKING OUTPUTS\n\n    if ll_end &lt; ll_start:\n        self.msg_err(\"Warning! Optimization seems to have diverged. Defaulting to seed params. \\n\"\n                     \"Please consider running with different optim_init inputs\")\n        estmap_params = seed_params\n    return estmap_params\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.hessian_scan.make_grid","title":"<code>make_grid(data, seed_params=None, interp_scale='log')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data</code> required <code>seed_params</code> <code>None</code> <code>interp_scale</code> <code>'log'</code> <p>Returns:</p> Type Description Source code in <code>litmus/fitting_methods.py</code> <pre><code>def make_grid(self, data, seed_params=None, interp_scale='log'):\n    \"\"\"\n    :param data:\n    :param seed_params:\n    :param interp_scale:\n    :return:\n    \"\"\"\n    # todo - reformat this and the make_grid for better consistency in drawing from estmap and seed params\n\n    assert interp_scale in ['log', 'linear'], \"Interp scale was %s, must be in 'log' or 'linear'\" % interp_scale\n\n    if not self.is_ready: self.readyup()\n\n    if 'lag' in self.stat_model.fixed_params():\n        lags = np.array([np.mean(self.stat_model.prior_ranges['lag'])])\n        self.Nlags = 1\n        self.readyup()\n        return lags\n\n    # If no seed parameters specified, use stored\n    if seed_params is None:\n        seed_params = self.estmap_params\n\n    # If these params are incomplete, use find_seed to complete them\n    if seed_params.keys() != self.stat_model.paramnames():\n        seed_params, llstart = self.stat_model.find_seed(data, guesses=self.init_samples, fixed=seed_params)\n\n    lags = np.linspace(*self.stat_model.prior_ranges['lag'], int(self.Nlags * self.grid_firstdepth) + 1,\n                       endpoint=False)[1:]\n    lag_terp = np.linspace(*self.stat_model.prior_ranges['lag'], self.grid_Nterp)\n\n    log_density_all, lags_all = np.empty(shape=(1,)), np.empty(shape=(1,))\n    for i in range(self.grid_depth):\n        params = _utils.dict_extend(seed_params, {'lag': lags})\n        log_density_all = np.concatenate([log_density_all, self.stat_model.log_density(params, data)])\n        lags_all = np.concatenate([lags_all, lags])\n        I = lags_all.argsort()\n        log_density_all, lags_all = log_density_all[I], lags_all[I]\n\n        if interp_scale == 'linear':\n\n            density = np.exp(log_density_all - log_density_all.max())\n\n            # Linearly interpolate the density profile\n            density_terp = np.interp(lag_terp, lags_all, density, left=0, right=0)\n            density_terp /= density_terp.sum()\n\n\n        elif interp_scale == 'log':\n\n            density = np.exp(log_density_all - log_density_all.max())\n\n            # Linearly interpolate the density profile\n            log_density_terp = np.interp(lag_terp, log_density_all - log_density_all.max(), density,\n                                         left=log_density_all[0], right=log_density_all[-1])\n            density_terp = np.exp(log_density_terp)\n            density_terp /= density_terp.sum()\n\n        gets = np.linspace(0, 1, self.grid_Nterp)\n        percentiles = np.cumsum(density_terp) * self.grid_bunching + gets * (1 - self.grid_bunching)\n        percentiles /= percentiles.max()\n\n        lags = np.interp(np.linspace(0, 1, self.Nlags), percentiles, lag_terp,\n                         left=lag_terp.min(),\n                         right=lag_terp.max()\n                         )\n\n    return lags\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.hessian_scan.diagnostics","title":"<code>diagnostics(plot=True)</code>","text":"<p>Runs some diagnostics for convergence</p> <p>Returns:</p> Type Description Source code in <code>litmus/fitting_methods.py</code> <pre><code>def diagnostics(self, plot=True):\n    '''\n    Runs some diagnostics for convergence\n    :return:\n    '''\n\n    loss = self.log_evidences_uncert\n\n    lagplot = self.scan_peaks['lag']\n    I = self.scan_peaks['lag'].argsort()\n    lagplot = lagplot[I]\n    Y = self.estmap_tol[I]\n\n    # ---------\n    fig = plt.figure()\n    plt.ylabel(\"Loss Norm, $ \\\\vert \\Delta x / \\sigma_x \\\\vert$\")\n    plt.xlabel(\"Scan Lag No.\")\n    plt.plot(lagplot, loss, 'o-', c='k', label=\"Scan Losses\")\n    plt.scatter(self.estmap_params['lag'], Y, c='r', marker='x', s=40, label=\"Initial MAP Scan Loss\")\n    plt.axhline(self.opt_tol, ls='--', c='k', label=\"Nominal Tolerance Limit\")\n    plt.legend(loc='best')\n\n    fig.text(.5, .05, \"How far each optimization slice is from its peak. Lower is good.\", ha='center')\n    plt.yscale('log')\n    plt.grid()\n    plt.show()\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.SVI_scan","title":"<code>SVI_scan(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>hessian_scan</code></p> <p>An alternative to hessian_scan that fits each slice with stochastic variational inference instead of the laplace approximation. Typically slower, but more robust against numerical failure in low SNR signals and gives more accurate evidence estimates.</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n\n    self._default_params |= {\n        'ELBO_threshold': 100.0,\n        'ELBO_optimstep': 5E-3,\n        'ELBO_particles': 128,\n        'ELBO_Nsteps': 128,\n        'ELBO_Nsteps_init': 1_000,\n        'ELBO_fraction': 0.25,\n    }\n\n    super().__init__(**args_in)\n\n    # -----------------------------\n\n    self.name = \"SVI Scan Fitting Procedure\"\n\n    self.diagnostic_losses = []\n    self.diagnostic_loss_init = []\n    self.diagnostic_ints = []\n</code></pre>"},{"location":"fitting_methods/#litmus.fitting_methods.JAVELIKE","title":"<code>JAVELIKE(stat_model: stats_model, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=False, **fit_params)</code>","text":"<p>               Bases: <code>fitting_procedure</code></p> <p>A direct MCMC implementation using the AEIS in the style of JAVELIN Note that, because NumPyro fits in the unconstrained domain while JAVELIN fits in the constrained domain, the behaviour of the two will be slightly different near the prior boundaries.</p> <p>Note that this is for example / comparison only, and should not be used for actual fitting as it cannot handle the multimodal distributions of seasonal lightcurves</p> Source code in <code>litmus/fitting_methods.py</code> <pre><code>def __init__(self, stat_model: stats_model,\n             out_stream=sys.stdout, err_stream=sys.stderr,\n             verbose=True, debug=False, **fit_params):\n    args_in = {**locals(), **fit_params}\n    del args_in['self']\n    del args_in['__class__']\n    del args_in['fit_params']\n\n    if not hasattr(self, '_default_params'):\n        self._default_params = {}\n    self._default_params |= {\n        'alpha': 2.0,\n        'num_chains': 256,\n        'num_samples': 200_000 // 256,\n        'num_warmup': 5_000,\n    }\n\n    self.sampler: numpyro.infer.MCMC = None\n    self.kernel: numpyro.infer.AEIS = None\n    self.limited_model: Callable = None\n\n    super().__init__(**args_in)\n\n    # -----------------------------\n\n    self.name = \"AEIS JAVELIN Emulator fitting Procedure\"\n</code></pre>"},{"location":"lightcurve/","title":"<code>litmus.lightcurve</code>","text":"<p>               Bases: <code>object</code></p> <p>A wrapper class for lightcurves. Construct /w array-like inputs for time, signal and error (optional) like:    lightcurve(T, Y, E) or:     lightcurve(T, Y) Which yields E=0 for all {T,Y}</p> <p>Supports array-like addition and float-like addition / multiplication</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def __init__(self, T, Y, E=None):\n    self.T = np.array(T, dtype=np.float64)\n    self.Y = np.array(Y, dtype=np.float64)\n    if E is None:\n        self.E = np.zeros_like(T)\n    else:\n        self.E = E\n\n    self._data = np.vstack(self.values()).T\n\n    self._norm_mean, self._norm_amp = 0.0, 1.0\n    self.normalized = False\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.keys","title":"<code>keys() -&gt; [str, str, str]</code>","text":"<p>Returns the string-like names of the lightcurve's attributes</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def keys(self) -&gt; [str, str, str]:\n    \"\"\"\n    Returns the string-like names of the lightcurve's attributes\n    \"\"\"\n    return [\"T\", \"Y\", \"E\"]\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.values","title":"<code>values() -&gt; (ArrayN, ArrayN, ArrayN)</code>","text":"<p>Returns the lightcurves' value series' in the order of keys</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def values(self) -&gt; (ArrayN, ArrayN, ArrayN):\n    \"\"\"\n    Returns the lightcurves' value series' in the order of keys\n    \"\"\"\n    return [self[key] for key in self.keys()]\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.normalize","title":"<code>normalize() -&gt; Self</code>","text":"<p>Esimates the mean and amplitude of the lighturve assuming uncorrelated measurements Returns a lightcurve object with this normalization</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def normalize(self) -&gt; Self:\n    \"\"\"\n    Esimates the mean and amplitude of the lighturve assuming uncorrelated measurements\n    Returns a lightcurve object with this normalization\n    \"\"\"\n\n    if self.normalized: return self\n\n    # Check if have errorbars\n    no_errs = False\n    E = self.E\n    if max(E)== 0:\n        no_errs = True\n        E = np.ones_like(self.E)\n\n    # Get initial guess assuming no scatter\n    w = E ** -2\n    mean0 = np.average(self.Y, weights=w)\n    var0 = np.average((self.Y - mean0) ** 2, weights=w)\n\n    if no_errs:\n        meanbest, varbest = mean0, var0\n    else:\n        L = lambda X: ((self.Y - X[0]) ** 2 / (self.E ** 2 + X[1]) + np.log(self.E ** 2 + X[1])).sum()\n        meanbest, varbest = optimize.minimize(L, np.array([mean0, var0]), method='Nelder-Mead').x\n\n    # Make and return copy\n    out = copy(self)\n    out -= meanbest\n    out /= np.sqrt(varbest)\n\n    # If any errors, revert to simple estiamte\n    if np.any(np.isnan(out._data)):\n        meanbest, varbest = mean0, var0\n        out = copy(self)\n        out -= meanbest\n        out /= np.sqrt(varbest)\n\n    # Store normalizing values for later\n    out._norm_mean = meanbest\n    out._norm_amp = np.sqrt(varbest)\n\n    out.normalized = True\n\n    return out\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.unnormalize","title":"<code>unnormalize() -&gt; Self</code>","text":"<p>Reverses the effects of lightcurve.normalize(). Returns a lightcurve object with mean and amplitude prior to normalize()</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def unnormalize(self) -&gt; Self:\n    \"\"\"\n    Reverses the effects of lightcurve.normalize().\n    Returns a lightcurve object with mean and amplitude prior to normalize()\n    \"\"\"\n    out = copy(self)\n    out *= self._norm_amp\n    out += self._norm_mean\n    out._norm_amp = 1.0\n    out._norm_mean = 0.0\n    out.normalized = False\n    return out\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.delayed_copy","title":"<code>delayed_copy(lag=0.0, Tmin=None, Tmax=None) -&gt; Self</code>","text":"<p>Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax] and offset by lag</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def delayed_copy(self, lag=0.0, Tmin=None, Tmax=None) -&gt; Self:\n    \"\"\"\n    Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax] and offset by lag\n    \"\"\"\n    if Tmin is None: Tmin = self.T.min()\n    if Tmax is None: Tmax = self.T.max()\n    I = np.where((self.T + lag &gt; Tmin) * (self.T + lag &lt; Tmax))[0]\n\n    return (lightcurve(T=self.T[I] + lag,\n                       Y=self.Y[I],\n                       E=self.E[I]\n                       ))\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.trimmed_copy","title":"<code>trimmed_copy(Tmin=None, Tmax=None) -&gt; Self</code>","text":"<p>Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax]</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def trimmed_copy(self, Tmin=None, Tmax=None) -&gt; Self:\n    \"\"\"\n    Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax]\n    \"\"\"\n    return self.delayed_copy(0, Tmin, Tmax)\n</code></pre>"},{"location":"lightcurve/#litmus.lightcurve.plot","title":"<code>plot(axis=None, show=True, **kwargs) -&gt; None</code>","text":"<p>Plots an errorbar series to a matplotlib axis. If show=True, will plt.show() after plotting. If axis is None, will create a new figure. Pass in any plotting kwargs for plt.errorbar at **kwargs</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def plot(self, axis=None, show=True, **kwargs) -&gt; None:\n    \"\"\"\n    Plots an errorbar series to a matplotlib axis.\n    If show=True, will plt.show() after plotting.\n    If axis is None, will create a new figure.\n    Pass in any plotting kwargs for plt.errorbar at **kwargs\n    \"\"\"\n    if axis is None:\n        plt.figure()\n        axis = plt.gca()\n        axis.set_xlabel(\"T\")\n        axis.set_Ylabel(\"Y\")\n    axis.errorbar(self.T, self.Y, self.E, fmt='none', **kwargs)\n\n    if show: plt.show()\n</code></pre>"},{"location":"lin_scatter/","title":"<code>litmus.lin_scatter</code>","text":""},{"location":"lin_scatter/#litmus.lin_scatter.linscatter","title":"<code>linscatter(X: np.array, Y: np.array, N: int) -&gt; np.ndarray[Any, np.float64]</code>","text":"<p>For some time series {X,Y}, returns N samples that are distributed along X with linear interpolation</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>X values</p> required <code>Y</code> <code>array</code> <p>Y values</p> required <code>N</code> <code>int</code> <p>Number of samples</p> required <p>Returns:</p> Type Description <code>ndarray[Any, float64]</code> <p>1D numpy array of samples along X</p> Source code in <code>litmus/lin_scatter.py</code> <pre><code>def linscatter(X: np.array, Y: np.array, N: int) -&gt; np.ndarray[Any, np.float64]:\n    '''\n    For some time series {X,Y}, returns N samples that are distributed along X with linear interpolation\n    :param X: X values\n    :param Y: Y values\n    :param N: Number of samples\n    :return: 1D numpy array of samples along X\n    '''\n\n    dx = np.array([X[0] - X[1], X[2] - X[1]])\n    dy = np.array([Y[0] - Y[1], Y[2] - Y[1]])\n    dx, dy = dx[dx.argsort()], dy[dx.argsort()]\n\n    weight_leftright = abs((Y[1] + dy / 2.0) * dx)\n    weight_leftright /= weight_leftright.sum()\n\n    leftright = np.random.choice([0, 1], replace=True, size=N, p=weight_leftright)\n\n    DX, DY = dx[leftright], dy[leftright]\n    YBAR = Y[1] + DY / 2\n    c1, c2 = YBAR / DY, Y[1] / DY\n\n    CDF = np.random.rand(N)\n\n    # todo - this throws an error because is evaluates the first branch in full. Find a way to suppress.\n    Xshift = np.where(DY != 0,\n                      np.sign(DY) * np.sqrt(CDF * c1 * 2 + (c2) ** 2) - c2,\n                      CDF\n                      )\n    Xshift = Xshift * DX\n\n    return Xshift\n</code></pre>"},{"location":"lin_scatter/#litmus.lin_scatter.expscatter","title":"<code>expscatter(X: np.array, Y: np.array, N) -&gt; np.ndarray[Any, np.float64]</code>","text":"<p>For some time series {X,Y}, returns N samples that are distributed along X with log-linear interpolation</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>X values</p> required <code>Y</code> <code>array</code> <p>Y values</p> required <code>N</code> <p>Number of samples</p> required <p>Returns:</p> Type Description <code>ndarray[Any, float64]</code> <p>1D numpy array of samples along X</p> Source code in <code>litmus/lin_scatter.py</code> <pre><code>def expscatter(X: np.array, Y: np.array, N) -&gt; np.ndarray[Any, np.float64]:\n    '''\n    For some time series {X,Y}, returns N samples that are distributed along X with log-linear interpolation\n    :param X: X values\n    :param Y: Y values\n    :param N: Number of samples\n    :return: 1D numpy array of samples along X\n    '''\n\n    dx = np.array([X[0] - X[1], X[2] - X[1]])\n    dy = np.array([Y[0] - Y[1], Y[2] - Y[1]])\n    dE = np.log(np.array([Y[0] / Y[1], Y[2] / Y[1]]))\n    dx, dy, dE = dx[dx.argsort()], dy[dx.argsort()], dE[dx.argsort()]\n\n    weight_leftright = abs(dx * dy / dE)\n\n    if dy[0] == 0: weight_leftright[0] = abs(dx[0] * Y[1])\n    if dy[1] == 0: weight_leftright[1] = abs(dx[1] * Y[1])\n\n\n    weight_leftright /= weight_leftright.sum()\n\n\n    leftright = np.random.choice([0, 1], replace=True, size=N, p=weight_leftright)\n\n    DX, DY, DE = dx[leftright], dy[leftright], dE[leftright]\n\n    CDF = np.random.rand(N)\n\n    # todo - this throws an error because is evaluates the first branch in full. Find a way to suppress.\n    Xshift = np.where(DY != 0,\n                      np.log(CDF * DY / Y[1] + 1) / DE,\n                      CDF\n                      )\n\n    Xshift = Xshift * DX\n\n    return Xshift\n</code></pre>"},{"location":"litmusclass/","title":"<code>litmus.litmusclass</code>","text":"<p>litmus.py</p> <p>Contains the main litmus object class, which acts as a user-friendly interface with the models statistical models and fitting procedure. In future versions, this will also give access to the GUI.</p> <p>todo     - This entire class to be re-done to take multiple models instead of multiple lightcurves     - Possibly add hdf5 saving to chain output     - Maybe add save_litmus() /w pickling?     - Need to have better handling of the \"fitting method inherit\" feature, especially with refactor / redo     -</p>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS","title":"<code>LITMUS(fitproc: fitting_procedure = None)</code>","text":"<p>               Bases: <code>logger</code></p> <p>A front-facing UI class for interfacing with the fitting procedures.</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def __init__(self, fitproc: fitting_procedure = None):\n\n    logger.__init__(self)\n    # ----------------------------\n\n    if fitproc is None:\n        self.msg_err(\"Didn't set a fitting method, using GP_simple\")\n        self.model = models.GP_simple()\n\n        self.msg_err(\"Didn't set a fitting method, using hessian scan\")\n\n        fitproc = fitting_methods.hessian_scan(stat_model=self.model)\n\n    self.model = fitproc.stat_model\n    self.fitproc = fitproc\n\n    # ----------------------------\n    self.lightcurves = []\n    self.data = None\n\n    self.Nsamples = 50_000\n    self.samples = {}\n    self.prior_samples = self.model.prior_sample(self.Nsamples)\n    self.C = ChainConsumer()\n\n    self.C.set_override(ChainConfig(smooth=0, linewidth=2, plot_cloud=True, shade_alpha=0.5))\n\n    # self.C.add_chain(Chain(samples=DataFrame.from_dict(self.prior_samples), name=\"Prior\", color='gray'))\n    if self.fitproc.has_run:\n        self.samples = self.fitproc.get_samples(self.Nsamples)\n        self.samples = self.fitproc.get_samples(self.Nsamples)\n        self.C.add_chain(Chain(samples=DataFrame.from_dict(self.samples), name=\"Lightcurves %i-%i\"))\n        self.msg_err(\"Warning! LITMUS object built on pre-run fitting_procedure. May have unexpected behaviour.\")\n\n    return\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.add_lightcurve","title":"<code>add_lightcurve(lc: lightcurve)</code>","text":"<p>Add a lightcurve 'lc' to the LITMUS object</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def add_lightcurve(self, lc: lightcurve):\n    \"\"\"\n    Add a lightcurve 'lc' to the LITMUS object\n    \"\"\"\n    self.lightcurves.append(lc)\n    return\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.remove_lightcurve","title":"<code>remove_lightcurve(i: int) -&gt; None</code>","text":"<p>Remove lightcurve of index 'i' from the LITMUS object</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def remove_lightcurve(self, i: int) -&gt; None:\n    \"\"\"\n    Remove lightcurve of index 'i' from the LITMUS object\n    \"\"\"\n    N = len(self.lightcurves)\n\n    if i &lt; N:\n        del self.lightcurves[i]\n    else:\n        self.msg_err(\"Tried to delete lightcurve %i but only have %i lightcurves. Skipping\" % (i, N))\n    return\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.prefit","title":"<code>prefit(i=0, j=1)</code>","text":"<p>Performs the full fit for the chosen stats model and fitting method.</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def prefit(self, i=0, j=1):\n    \"\"\"\n    Performs the full fit for the chosen stats model and fitting method.\n    \"\"\"\n\n    lc_1, lc_2 = self.lightcurves[i], self.lightcurves[j]\n    self.data = self.model.lc_to_data(lc_1, lc_2)\n\n    self.fitproc.prefit(lc_1, lc_2)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.fit","title":"<code>fit(i=0, j=1) -&gt; None</code>","text":"<p>Performs the full fit for the chosen stats model and fitting method.</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def fit(self, i=0, j=1) -&gt; None:\n    \"\"\"\n    Performs the full fit for the chosen stats model and fitting method.\n    \"\"\"\n\n    lc_1, lc_2 = self.lightcurves[i], self.lightcurves[j]\n    self.data = self.model.lc_to_data(lc_1, lc_2)\n\n    self.fitproc.fit(lc_1, lc_2)\n\n    self.samples = self.fitproc.get_samples(self.Nsamples)\n    self.C.add_chain(Chain(samples=DataFrame.from_dict(self.samples), name=\"Lightcurves %i-%i\" % (i, j)))\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.save_chain","title":"<code>save_chain(path: str = None, headings: bool = True) -&gt; None</code>","text":"<p>Saves the litmus's output chains to a .csv file at \"path\" If headings=True (default) then the names of the parameters will be written to the first row of the tile</p>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.save_chain--todo-this-needs-updating","title":"todo - this needs updating","text":"Source code in <code>litmus/litmusclass.py</code> <pre><code>def save_chain(self, path: str = None, headings: bool = True) -&gt; None:\n    \"\"\"\n    Saves the litmus's output chains to a .csv file at \"path\"\n    If headings=True (default) then the names of the parameters will be written to the first row of the tile\n    #todo - this needs updating\n    \"\"\"\n    if path is None:\n        path = \"./%s_%s.csv\" % (self.model.name, self.fitproc.name)\n        if path[-4:] != \".csv\": path += \".csv\"\n\n    rows = zip(*self.samples.values())\n    with open(path, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        # Write header\n        if headings: writer.writerow(self.samples.keys())\n        # Write rows\n        writer.writerows(rows)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.read_chain","title":"<code>read_chain(path: str, header: Iterable[str] | None = None)</code>","text":""},{"location":"litmusclass/#litmus.litmusclass.LITMUS.read_chain--todo-needs-updating","title":"todo needs updating","text":"Source code in <code>litmus/litmusclass.py</code> <pre><code>def read_chain(self, path: str, header: Iterable[str] | None = None):\n    \"\"\"\n    #todo needs updating\n    \"\"\"\n    # Reading the CSV into a DataFrame\n    df = pd.read_csv(path)\n\n    if header is None:\n        keys = df.columns\n    else:\n        keys = header.copy()\n\n    # Converting DataFrame to dictionary of numpy arrays\n    out = {col: df[col].to_numpy() for col in keys}\n\n    if out.keys() &lt;= set(self.fitproc.stat_model.paramnames()):\n        self.samples = out\n        self.msg_run(\"Loaded chain /w headings\", *keys)\n    else:\n        self.msg_err(\"Tried to load chain with different parameter names to model\")\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.config","title":"<code>config(**kwargs)</code>","text":"<p>Quick and easy way to pass arguments to the chainconsumer object. Allows editing while prote</p> Source code in <code>litmus/litmusclass.py</code> <pre><code>def config(self, **kwargs):\n    '''\n    Quick and easy way to pass arguments to the chainconsumer object.\n    Allows editing while prote\n    '''\n    self.C.set_override(ChainConfig(**kwargs))\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.plot_lightcurves","title":"<code>plot_lightcurves(model_no: int = 0, Nsamples: int = 1, Tspan: None | list[float, float] = None, Nplot: int = 1024, dir: str | None = None, show: bool = True) -&gt; matplotlib.figure.Figure()</code>","text":"<p>Plots the interpolated lightcurves for one of the fitted models</p> <p>Parameters:</p> Name Type Description Default <code>model_no</code> <code>int</code> <p>Which model to plot the lightcurves for</p> <code>0</code> <code>Nsamples</code> <code>int</code> <p>Number of posterior samples to draw from when plotting</p> <code>1</code> <code>Tspan</code> <code>None | list[float, float]</code> <p>Span of time values to plot over. If None, will use the max / min times of lc_1 and lc_2</p> <code>None</code> <code>Nplot</code> <code>int</code> <p>Number of points in the interpolated lightcurve</p> <code>1024</code> <code>dir</code> <code>str | None</code> <p>If not None, will save to this filepath</p> <code>None</code> <code>show</code> <code>bool</code> <p>If True, will plt.show() the plot</p> <code>True</code> Source code in <code>litmus/litmusclass.py</code> <pre><code>def plot_lightcurves(self, model_no: int =0, Nsamples: int = 1, Tspan: None | list[float, float] = None, Nplot: int = 1024,\n                     dir: str | None = None, show: bool = True) -&gt; matplotlib.figure.Figure():\n    \"\"\"\n    Plots the interpolated lightcurves for one of the fitted models\n    :param model_no: Which model to plot the lightcurves for\n    :parameter Nsamples: Number of posterior samples to draw from when plotting\n    :parameter Tspan: Span of time values to plot over. If None, will use the max / min times of lc_1 and lc_2\n    :parameter Nplot: Number of points in the interpolated lightcurve\n    :parameter dir: If not None, will save to this filepath\n    :parameter show: If True, will plt.show() the plot\n    \"\"\"\n\n    self.msg_err(\"plot_lightcurve() not yet implemented\")\n    fig = plt.figure()\n    return fig\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.plot_parameters","title":"<code>plot_parameters(model_no: int | None = None, Nsamples: int = None, CC_kwargs: dict = {}, show: bool = True, prior_extents: bool = False, dir: str | None = None) -&gt; matplotlib.figure.Figure</code>","text":"<p>Creates a nicely formatted chainconsumer plot of the parameters</p> <p>Parameters:</p> Name Type Description Default <code>model_no</code> <code>int | None</code> <p>Which model to plot the lightcurves for. If None, will plot for all</p> <code>None</code> <code>Nsamples</code> <code>int</code> <p>Number of posterior samples to draw from when plotting</p> <code>None</code> <code>CC_kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the chainconsumer constructor</p> <code>{}</code> <code>show</code> <code>bool</code> <p>If True, will show the plot</p> <code>True</code> <code>prior_extents</code> <code>bool</code> <p>If True, will use the model prior range for the axes limits (Defaults to false if multiple models used)</p> <code>False</code> <code>dir</code> <code>str | None</code> <p>If not None, will save to this filepath Returns the matplotlib figure  # todo - refactor for multi-model implementation</p> <code>None</code> Source code in <code>litmus/litmusclass.py</code> <pre><code>def plot_parameters(self, model_no: int | None = None, Nsamples: int = None, CC_kwargs: dict = {},\n                    show: bool = True,\n                    prior_extents: bool = False, dir: str | None = None) -&gt; matplotlib.figure.Figure:\n    \"\"\"\n    Creates a nicely formatted chainconsumer plot of the parameters\n    :param model_no: Which model to plot the lightcurves for. If None, will plot for all\n    :param Nsamples: Number of posterior samples to draw from when plotting\n    :parameter CC_kwargs: Keyword arguments to pass to the chainconsumer constructor\n    :parameter show: If True, will show the plot\n    :parameter prior_extents: If True, will use the model prior range for the axes limits (Defaults to false if multiple models used)\n    :parameter dir: If not None, will save to this filepath\n    Returns the matplotlib figure\n\n    # todo - refactor for multi-model implementation\n    \"\"\"\n\n    if Nsamples is not None and Nsamples != self.Nsamples:\n        C = ChainConsumer()\n        samples = self.fitproc.get_samples(Nsamples, **CC_kwargs)\n        C.add_chain(Chain(samples=DataFrame.from_dict(samples), name='samples'))\n    else:\n        C = self.C\n\n    if prior_extents:\n        _config = PlotConfig(extents=self.model.prior_ranges, summarise=True,\n                             **CC_kwargs)\n    else:\n        _config = PlotConfig(summarise=True,\n                             **CC_kwargs)\n    C.plotter.set_config(_config)\n    params_toplot = [param for param in self.model.free_params() if self.samples[param].ptp() != 0]\n    if len(params_toplot) == 0:\n        fig = plt.figure()\n        if show: plt.show()\n        return fig\n\n    try:\n        fig = C.plotter.plot(columns=params_toplot,\n                             )\n    except:\n        fig = plt.figure()\n        fig.text(0.5, 0.5, \"Something wrong with plotter\")\n    fig.tight_layout()\n    if show: fig.show()\n\n    if dir is not None:\n        plt.savefig(dir)\n\n    return fig\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.lag_plot","title":"<code>lag_plot(Nsamples: int = None, show: bool = True, extras: bool = True, prior_extents=False, dir: str | None = None) -&gt; matplotlib.figure.Figure</code>","text":"<p>Creates a nicely formatted chainconsumer plot of the marginalized lag plot</p> <p>Parameters:</p> Name Type Description Default <code>Nsamples</code> <code>int</code> <p>Number of posterior samples to draw from when plotting</p> <code>None</code> <code>show</code> <code>bool</code> <p>If True, will show the plot</p> <code>True</code> <code>extras</code> <code>bool</code> <p>If True, will add any fitting method specific extras to the plot</p> <code>True</code> <code>dir</code> <code>str | None</code> <p>If not None, will save to this filepath</p> <code>None</code> <code>prior_extents</code> <p>If True, will use the model prior range for the axes limits (Defaults to false if multiple models used)  Returns the matplotlib figure</p> <code>False</code> Source code in <code>litmus/litmusclass.py</code> <pre><code>def lag_plot(self, Nsamples: int = None, show: bool = True, extras: bool = True, prior_extents=False,\n             dir: str | None = None, ) -&gt; matplotlib.figure.Figure:\n    \"\"\"\n    Creates a nicely formatted chainconsumer plot of the marginalized lag plot\n    :param Nsamples: Number of posterior samples to draw from when plotting\n    :parameter show: If True, will show the plot\n    :parameter extras: If True, will add any fitting method specific extras to the plot\n    :parameter dir: If not None, will save to this filepath\n    :parameter prior_extents: If True, will use the model prior range for the axes limits (Defaults to false if multiple models used)\n\n    Returns the matplotlib figure\n    \"\"\"\n    if 'lag' not in self.model.free_params():\n        self.msg_err(\"Can't plot lags for a model without lags.\")\n        return\n\n    if Nsamples is not None and Nsamples != self.Nsamples:\n        C = ChainConsumer()\n        samples = self.fitproc.get_samples(Nsamples)\n        C.add_chain(Chain(samples=DataFrame.from_dict(samples), name=\"lags\"))\n    else:\n        C = self.C\n\n    _config = PlotConfig(extents=self.model.prior_ranges, summarise=True)\n    C.plotter.set_config(_config)\n    fig = C.plotter.plot_distributions(columns=['lag'], figsize=(8, 4))\n    if prior_extents: fig.axes[0].set_xlim(*self.model.prior_ranges['lag'])\n    fig.axes[0].set_ylim(*fig.axes[0].get_ylim())\n    fig.tight_layout()\n\n    fig.axes[0].grid()\n\n    # Method specific plotting of fun stuff\n    if extras:\n        if isinstance(self.fitproc, fitting_methods.hessian_scan):\n            X, logY = self.fitproc._get_slices('lags', 'logZ')\n\n            if self.fitproc.interp_scale == 'linear':\n                Y = np.exp(logY - logY.max())\n                Y /= np.trapz(Y, X)\n                fig.axes[0].plot(X, Y)\n\n            elif self.fitproc.interp_scale == 'log':\n                Xterp = np.linspace(*self.model.prior_ranges['lag'], self.Nsamples)\n                logYterp = np.interp(Xterp, X, logY, left=logY[0], right=logY[-1])\n                Yterp = np.exp(logYterp - logYterp.max())\n                Yterp /= np.trapz(Yterp, Xterp)\n                fig.axes[0].plot(Xterp, Yterp)\n\n            plt.scatter(self.fitproc.lags, np.zeros_like(self.fitproc.lags), c='red', s=20)\n            plt.scatter(X, np.zeros_like(X), c='black', s=20)\n    if dir is not None:\n        plt.savefig(dir)\n    if show: fig.show()\n    return (fig)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.LITMUS.diagnostic_plots","title":"<code>diagnostic_plots(dir: str | None = None, show: bool = False, **kwargs)</code>","text":"<p>Generates a diagnostic plot window</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str | None</code> <p>If not None, will save to this filepath</p> <code>None</code> <code>show</code> <code>bool</code> <p>If True, will show the plot  If dir!=None, will plt.savefig to the filepath 'dir' with **kwargs</p> <code>False</code> Source code in <code>litmus/litmusclass.py</code> <pre><code>def diagnostic_plots(self, dir: str | None = None, show: bool = False, **kwargs):\n    \"\"\"\n    Generates a diagnostic plot window\n    :param dir: If not None, will save to this filepath\n    :param show: If True, will show the plot\n\n    If dir!=None, will plt.savefig to the filepath 'dir' with **kwargs\n    \"\"\"\n    if hasattr(self.fitproc, \"diagnostics\"):\n        self.fitproc.diagnostics()\n    else:\n        self.msg_err(\"diagnostic_plots() not yet implemented for fitting method %s\" % (self.fitproc.name))\n\n    if dir is not None:\n        plt.savefig(dir, **kwargs)\n\n    if show: plt.show()\n\n    return\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.isiter","title":"<code>isiter(x: any) -&gt; bool</code>","text":"<p>Checks to see if an object is itterable</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter(x: any) -&gt; bool:\n    '''\n    Checks to see if an object is itterable\n    '''\n    if type(x) == dict:\n        return len(x[list(x.keys())[0]]) &gt; 1\n    try:\n        iter(x)\n    except:\n        return (False)\n    else:\n        return (True)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.isiter_dict","title":"<code>isiter_dict(DICT: dict) -&gt; bool</code>","text":"<p>like isiter but for a dictionary. Checks only the first element in DICT.keys</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter_dict(DICT: dict) -&gt; bool:\n    '''\n    like isiter but for a dictionary. Checks only the first element in DICT.keys\n    '''\n\n    key = list(DICT.keys())[0]\n    if isiter(DICT[key]):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_dim","title":"<code>dict_dim(DICT: dict) -&gt; (int, int)</code>","text":"<p>Checks the first element of a dictionary and returns its length</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_dim(DICT: dict) -&gt; (int, int):\n    '''\n    Checks the first element of a dictionary and returns its length\n    '''\n\n    if isiter_dict(DICT):\n        firstkey = list(DICT.keys())[0]\n        return (len(list(DICT.keys())), len(DICT[firstkey]))\n    else:\n        return (len(list(DICT.keys())), 1)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_pack","title":"<code>dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array</code>","text":"<p>Packs a dictionary into an array format</p> <p>Parameters:</p> Name Type Description Default <code>DICT</code> <code>dict</code> <p>the dict to unpack</p> required <code>keys</code> <p>the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial</p> <code>None</code> <code>recursive</code> <p>whether to recurse into arrays</p> <code>True</code> <code>H</code> <p>Matrix to scale parameters by</p> <code>None</code> <code>d0</code> <p>Value to offset by before packing</p> <code>{}</code> <p>Returns:</p> Type Description <code>array</code> <p>(nkeys x len_array) np.arrayobject  X = H (d-d0)</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array:\n    '''\n    Packs a dictionary into an array format\n    :param DICT: the dict to unpack\n    :param keys: the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial\n    :param recursive: whether to recurse into arrays\n    :param H: Matrix to scale parameters by\n    :param d0: Value to offset by before packing\n    :return: (nkeys x len_array) np.arrayobject\n\n    X = H (d-d0)\n    '''\n\n    nokeys = True if keys is None else 0\n    keys = keys if keys is not None else DICT.keys()\n\n    if d0 is {}: d0 = {key:0 for key in keys}\n\n    for key in keys:\n        if key in DICT.keys() and key not in d0.keys(): d0 |= {key: 0.0}\n\n    if recursive and type(list(DICT.values())[0]) == dict:\n        out = np.array(\n            [dict_pack(DICT[key] - d0[key], keys=keys if not nokeys else None, recursive=recursive) for key in keys])\n    else:\n        if isiter(DICT[list(keys)[0]]):\n            out = np.array([[DICT[key][i] - d0[key] for i in range(dict_dim(DICT)[1])] for key in keys])\n        else:\n            out = np.array([DICT[key] - d0[key] for key in keys])\n\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_unpack","title":"<code>dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array</code>","text":"<p>Unpacks an array into a dict</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Array to unpack</p> required <code>keys</code> <code>[str]</code> <p>keys to unpack with</p> required <p>Returns:</p> Type Description <code>array</code> <p>Hinv(X) + x0</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array:\n    \"\"\"\n    Unpacks an array into a dict\n    :param X: Array to unpack\n    :param keys: keys to unpack with\n    :return:\n\n    Hinv(X) + x0\n    \"\"\"\n    if Hinv is not None: assert Hinv.shape[0] == len(keys), \"Size of H must be equal to number of keys in dict_unpack\"\n\n    if recursive and isiter(X[0]):\n        out = {key: dict_unpack(X[i], keys, recursive) for i, key in enumerate(list(keys))}\n    else:\n        X = X.copy()\n        if Hinv is not None:\n            X = np.dot(Hinv, X)\n        if x0 is not None:\n            X += x0\n        out = {key: X[i] for i, key in enumerate(list(keys))}\n\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_sortby","title":"<code>dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict</code>","text":"<p>Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both. Else, append un-sorted entries to end</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict:\n    \"\"\"\n    Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both.\n    Else, append un-sorted entries to end\n    \"\"\"\n    out = {key: A[key] for key in B if key in A}\n    if not match_only:\n        out |= {key: A[key] for key in A if key not in B}\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_extend","title":"<code>dict_extend(A: dict, B: dict = None) -&gt; dict</code>","text":"<p>Extends all single-length entries of a dict to match the length of a non-singular element</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>dict</code> <p>Dictionary whose elements are to be extended</p> required <code>B</code> <code>dict</code> <p>(optional) the array to extend by, equivalent to dict_extend(A|B)</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_extend(A: dict, B: dict = None) -&gt; dict:\n    '''\n    Extends all single-length entries of a dict to match the length of a non-singular element\n    :param A: Dictionary whose elements are to be extended\n    :param B: (optional) the array to extend by, equivalent to dict_extend(A|B)\n    :return:\n    '''\n\n    out = A.copy()\n    if B is not None: out |= B\n\n    to_extend = [key for key in out if not isiter(out[key])]\n    to_leave = [key for key in out if isiter(out[key])]\n\n    if len(to_extend) == 0: return out\n    if len(to_leave) == 0: return out\n\n    N = len(out[to_leave[0]])\n    for key in to_leave[1:]:\n        assert len(out[key]) == N, \"Tried to dict_extend() a dictionary with inhomogeneous lengths\"\n\n    for key in to_extend:\n        out[key] = np.array([A[key]] * N)\n\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_combine","title":"<code>dict_combine(X: [dict]) -&gt; {str: [float]}</code>","text":"<p>Combines an array, list etc of dictionary into a dictionary of arrays</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_combine(X: [dict]) -&gt; {str: [float]}:\n    '''\n    Combines an array, list etc of dictionary into a dictionary of arrays\n    '''\n\n    N = len(X)\n    keys = X[0].keys()\n\n    out = {key: np.zeros(N) for key in keys}\n    for n in range(N):\n        for key in keys:\n            out[key][n] = X[n][key]\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.dict_divide","title":"<code>dict_divide(X: dict) -&gt; [dict]</code>","text":"<p>Splits dict of arrays into array of dicts</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_divide(X: dict) -&gt; [dict]:\n    '''\n    Splits dict of arrays into array of dicts\n    '''\n\n    keys = list(X.keys())\n    N = len(X[keys[0]])\n\n    out = [{key: X[key][i] for key in X} for i in range(N)]\n\n    return (out)\n</code></pre>"},{"location":"litmusclass/#litmus.litmusclass.pack_function","title":"<code>pack_function(func, packed_keys: [str], fixed_values: dict = {}, invert: bool = False, jit: bool = False, H: np.array = None, d0: dict = {})</code>","text":"<p>Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly Takes a function f(D:dict, arg, kwargs) and returns f(X, D2, args, **kwargs), D2 is all elements of D not listed in 'packed_keys' or fixed_values.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>Function to be unpacked</p> required <code>packed_keys</code> <code>[str]</code> <p>Keys in 'D' to be packed in an array</p> required <code>fixed_values</code> <code>dict</code> <p>Elements of 'D' to be fixed</p> <code>{}</code> <code>invert</code> <code>bool</code> <p>If true, will 'flip' the function upside down</p> <code>False</code> <code>jit</code> <code>bool</code> <p>If true, will 'jit' the function</p> <code>False</code> <code>H</code> <code>array</code> <p>(optional) scaling matrix to reparameterize H with</p> <code>None</code> <code>x0</code> <p>(optional) If given, will center the reparameterized  function at x0</p> required Source code in <code>litmus/_utils.py</code> <pre><code>def pack_function(func, packed_keys: ['str'], fixed_values: dict = {}, invert: bool = False, jit: bool = False,\n                  H: np.array = None, d0: dict = {}):\n    '''\n    Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly\n    Takes a function f(D:dict, *arg, **kwargs) and returns f(X, D2, *args, **kwargs), D2 is all elements of D not\n    listed in 'packed_keys' or fixed_values.\n\n    :param func: Function to be unpacked\n    :param packed_keys: Keys in 'D' to be packed in an array\n    :param fixed_values: Elements of 'D' to be fixed\n    :param invert:  If true, will 'flip' the function upside down\n    :param jit: If true, will 'jit' the function\n    :param H: (optional) scaling matrix to reparameterize H with\n    :param x0: (optional) If given, will center the reparameterized  function at x0\n    '''\n\n    if H is not None:\n        assert H.shape[0] == len(packed_keys), \"Scaling matrix H must be same length as packed_keys\"\n    else:\n        H = jnp.eye(len(packed_keys))\n    d0 = {key: 0.0 for key in packed_keys} | d0\n    x0 = dict_pack(d0, packed_keys)\n\n    # --------\n\n    sign = -1 if invert else 1\n\n    # --------\n    def new_func(X, unpacked_params={}, *args, **kwargs):\n        X = jnp.dot(H, X - x0)\n        packed_dict = {key: x for key, x in zip(packed_keys, X)}\n        packed_dict |= unpacked_params\n        packed_dict |= fixed_values\n\n        out = func(packed_dict, *args, **kwargs)\n        return (sign * out)\n\n    # --------\n    if jit: new_func = jax.jit(new_func)\n\n    return (new_func)\n</code></pre>"},{"location":"logging/","title":"<code>litmus.logging</code>","text":"<p>logging.py</p> <p>Collection of logging functions in a handy inheritable class, to make it easier to edit later in one place</p>"},{"location":"logging/#litmus.logging.logger","title":"<code>logger(out_stream=sys.stdout, err_stream=sys.stderr, verbose: bool = True, debug: bool = False)</code>","text":"<p>Object class that contains methods for printing to debug, verbose and error streams. Somewhat a placeholder atm</p> Source code in <code>litmus/logging.py</code> <pre><code>def __init__(self, out_stream=sys.stdout, err_stream=sys.stderr, verbose: bool = True, debug: bool = False):\n    # ----------------------------\n\n    self.out_stream = out_stream\n    self.err_stream = err_stream\n    self.verbose = verbose\n    self.debug = debug\n</code></pre>"},{"location":"logging/#litmus.logging.logger.msg_err","title":"<code>msg_err(*x: str, end='\\n', delim=' ')</code>","text":"<p>Messages for when something has broken or been called incorrectly</p> Source code in <code>litmus/logging.py</code> <pre><code>def msg_err(self, *x: str, end='\\n', delim=' '):\n    \"\"\"\n    Messages for when something has broken or been called incorrectly\n    \"\"\"\n    if True:\n        for a in x:\n            print(a, file=self.err_stream, end=delim)\n\n    print(end, end='')\n    return\n</code></pre>"},{"location":"logging/#litmus.logging.logger.msg_run","title":"<code>msg_run(*x: str, end='\\n', delim=' ')</code>","text":"<p>Standard messages about when things are running</p> Source code in <code>litmus/logging.py</code> <pre><code>def msg_run(self, *x: str, end='\\n', delim=' '):\n    \"\"\"\n    Standard messages about when things are running\n    \"\"\"\n    if self.verbose:\n        for a in x:\n            print(a, file=self.out_stream, end=delim)\n\n    print(end, end='')\n    return\n</code></pre>"},{"location":"logging/#litmus.logging.logger.msg_verbose","title":"<code>msg_verbose(*x: str, end='\\n', delim=' ')</code>","text":"<p>Explicit messages to help debug when things are behaving strangely</p> Source code in <code>litmus/logging.py</code> <pre><code>def msg_verbose(self, *x: str, end='\\n', delim=' '):\n    \"\"\"\n    Explicit messages to help debug when things are behaving strangely\n    \"\"\"\n    if self.debug:\n        for a in x:\n            print(a, file=self.out_stream, end=delim)\n\n    print(end, end='')\n    return\n</code></pre>"},{"location":"mocks/","title":"<code>litmus.mocks</code>","text":"<p>Some handy sets of mock data for use in testing</p> <p>HM Apr 2024</p>"},{"location":"mocks/#litmus.mocks.mock","title":"<code>mock(seed=0, **kwargs)</code>","text":"<p>               Bases: <code>logger</code></p> <p>Handy class for making mock data. When calling with init,     defaultkwargs = {'tau':             400.0,                      'cadence':         [7, 30],                      'cadence_var':     [1, 5],                      'season':          180,                      'season_var':      14,                      'N':               2048,                      'maxtime':         360 * 5,                      'lag':             30,                      'E':               [0.01, 0.1],                      'E_var':           [0.0, 0.0]                      }</p> Source code in <code>litmus/mocks.py</code> <pre><code>def __init__(self, seed=0, **kwargs):\n    defaultkwargs = {'tau': 400.0,\n                     'cadence': [7, 30],\n                     'cadence_var': [1, 5],\n                     'season': 180,\n                     'season_var': 14,\n                     'N': 2048,\n                     'maxtime': 360 * 5,\n                     'lag': 30,\n                     'E': [0.01, 0.1],\n                     'E_var': [0.0, 0.0]\n                     }\n\n    logger.__init__(self)\n\n    self.seed = seed\n    self.lc, self.lc_1, self.lc_2 = None, None, None\n    self.lag = 0.0\n    kwargs = defaultkwargs | kwargs\n    self.args = {}\n\n    for key in ['cadence', 'cadence_var', 'E', 'E_var']:\n        if not (isiter(kwargs[key])): kwargs[key] = [kwargs[key], kwargs[key]]\n    for key, var in zip(kwargs.keys(), kwargs.values()):\n        self.__setattr__(key, var)\n        self.args[key] = var\n\n    self.generate(seed=seed)\n    return\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock.generate_true","title":"<code>generate_true(seed: int = 0) -&gt; (ArrayN, ArrayN)</code>","text":"<p>Generates an underlying true DRW signal and stores in the self attribute self.lc</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed for random generation</p> <code>0</code> <p>Returns:</p> Type Description <code>(ArrayN, ArrayN)</code> <p>Array tuple (T,Y), underlying curve extending to maxtime + 2 * lag</p> Source code in <code>litmus/mocks.py</code> <pre><code>def generate_true(self, seed: int = 0) -&gt; (ArrayN, ArrayN):\n    \"\"\"\n    Generates an underlying true DRW signal and stores in the self attribute self.lc\n    :param seed: seed for random generation\n    :return: Array tuple (T,Y), underlying curve extending to maxtime + 2 * lag\n    \"\"\"\n    T = np.linspace(0.0, self.maxtime + self.lag * 2, self.N)\n    Y = gp_realization(T, tau=self.tau, seed=seed).Y\n    self.lc = lightcurve(T, Y)  # .trim(Tmin=0, Tmax=self.maxtime)\n    return (T, Y)\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock.generate","title":"<code>generate(seed: int = 0) -&gt; (lightcurve, lightcurve)</code>","text":"<p>Generates a mock and sampled light-curve including a delayed response and stores in the self-attributes self.lc_1 and self.lc_2. Also returns as tuple (lc, lc_1, lc_2)</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed for random generation</p> <code>0</code> <p>Returns:</p> Type Description <code>(lightcurve, lightcurve)</code> <p>lightcurve object</p> Source code in <code>litmus/mocks.py</code> <pre><code>def generate(self, seed: int = 0) -&gt; (lightcurve, lightcurve):\n    \"\"\"\n    Generates a mock and sampled light-curve including a delayed response and stores in the self-attributes\n    self.lc_1 and self.lc_2. Also returns as tuple (lc, lc_1, lc_2)\n    :param seed: seed for random generation\n    :return: lightcurve object\n    \"\"\"\n\n    T, Y = self.generate_true(seed=seed)\n\n    T1 = mock_cadence(self.maxtime, seed, cadence=self.cadence[0], cadence_var=self.cadence_var[0],\n                      season=self.season, season_var=self.season_var,\n                      N=self.N)\n    T2 = mock_cadence(self.maxtime, seed, cadence=self.cadence[1], cadence_var=self.cadence_var[1],\n                      season=self.season, season_var=self.season_var,\n                      N=self.N)\n\n    Y1, Y2 = subsample(T, Y, T1), subsample(T + self.lag, Y, T2)\n    E1, E2 = [np.random.randn(len(x)) * ev + e for x, ev, e in zip([T1, T2], self.E_var, self.E)]\n\n    Y1 += np.random.randn(len(T1)) * abs(E1)\n    Y2 += np.random.randn(len(T2)) * abs(E2)\n\n    self.lc_1 = lightcurve(T1, Y1, E1)\n    self.lc_2 = lightcurve(T2, Y2, E2)\n\n    return (self.lc_1, self.lc_2)\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock.copy","title":"<code>copy(seed: int = None, **kwargs) -&gt; Self</code>","text":"<p>Returns a copy of the mock while over-writing certain params.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>int seed for random generation</p> <code>None</code> <code>kwargs</code> <p>kwargs to pass to the new lightcurve object, will overwrite self.kwargs in the copy</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of self with kwargs and seed changed accordingly</p> Source code in <code>litmus/mocks.py</code> <pre><code>def copy(self, seed: int = None, **kwargs) -&gt; Self:\n    \"\"\"\n    Returns a copy of the mock while over-writing certain params.\n    :param seed: int seed for random generation\n    :param kwargs: kwargs to pass to the new lightcurve object, will overwrite self.kwargs in the copy\n    :return: A copy of self with kwargs and seed changed accordingly\n    \"\"\"\n    if seed is None:\n        seed = self.seed\n\n    out = mock(seed=seed, **(self.args | kwargs))\n    return (out)\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock.swap_response","title":"<code>swap_response(other: lightcurve) -&gt; None</code>","text":"<p>Swaps the response lightcurves between this mock and its target. Over-writes target and self</p> Source code in <code>litmus/mocks.py</code> <pre><code>def swap_response(self, other: lightcurve) -&gt; None:\n    \"\"\"\n    Swaps the response lightcurves between this mock and its target.\n    Over-writes target and self\n    \"\"\"\n\n    self.lc_2, other.lc_2 = other.lc_2, self.lc_2\n    self.lc, other.lc = None, None\n    return\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock.plot","title":"<code>plot(axis: matplotlib.axes.Axes = None, true_args: dict = {}, series_args: dict = {}, show: bool = True) -&gt; matplotlib.figure.Figure</code>","text":"<p>Plots the lightcurves and subsamples</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Axes</code> <p>matplotlib axis to plot to. If none will create new</p> <code>None</code> <code>true_args</code> <code>dict</code> <p>matplotlib plotting kwargs for the true underlying lightcurve</p> <code>{}</code> <code>series_args</code> <code>dict</code> <p>matplotlib plotting kwargs for the observations</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plot axis</p> Source code in <code>litmus/mocks.py</code> <pre><code>def plot(self, axis: matplotlib.axes.Axes = None, true_args: dict = {}, series_args: dict = {},\n         show: bool = True) -&gt; matplotlib.figure.Figure:\n    \"\"\"\n    Plots the lightcurves and subsamples\n    :param axis: matplotlib axis to plot to. If none will create new\n    :param true_args: matplotlib plotting kwargs for the true underlying lightcurve\n    :param series_args: matplotlib plotting kwargs for the observations\n    :return: Plot axis\n    \"\"\"\n\n    # -----------------\n    # Make / get axis\n    if axis is None:\n        f = plt.figure()\n        axis = plt.gca()\n        axis.grid()\n        axis.set_xlabel(\"Time (days)\")\n        axis.set_ylabel(\"Signal Strength\")\n\n    # -----------------\n    # Plot underlying curves\n    true_args = {'lw': 0.5, 'c': ['tab:blue', 'tab:orange'], 'alpha': 0.3, 'label': ['True Signal', 'Response'],\n                 } | true_args\n    true_args_1 = true_args.copy()\n    true_args_2 = true_args.copy()\n\n    for key, val in zip(true_args.keys(), true_args.values()):\n        if isiter(val) and len(val) &gt; 1:\n            true_args_1[key] = true_args[key][0]\n            true_args_2[key] = true_args[key][1]\n        else:\n            true_args_1[key] = true_args[key]\n            true_args_2[key] = true_args[key]\n\n    if self.lc is not None:\n        lc_true_1, lc_true_2 = self.lc.delayed_copy(0, 0, self.maxtime), self.lc.delayed_copy(self.lag, 0,\n                                                                                              self.maxtime)\n\n        axis.plot(lc_true_1.T, lc_true_1.Y, **true_args_1)\n        axis.plot(lc_true_2.T, lc_true_2.Y, **true_args_2)\n\n    # -----------------\n    # Plot errorbars\n    series_args = {'c': ['tab:blue', 'tab:orange'], 'alpha': 1.0, 'capsize': 2, 'lw': 1.5,\n                   'label': [\"Signal\", \"Response\"]} | series_args\n    series_args_1 = series_args.copy()\n    series_args_2 = series_args.copy()\n\n    for key, val in zip(series_args.keys(), series_args.values()):\n        if isiter(val) and len(val) &gt; 1:\n            series_args_1[key] = series_args[key][0]\n            series_args_2[key] = series_args[key][1]\n        else:\n            series_args_1[key] = series_args[key]\n            series_args_2[key] = series_args[key]\n\n    axis.errorbar(self.lc_1.T, self.lc_1.Y, self.lc_1.E, fmt='none',\n                  **series_args_1\n                  )\n    axis.errorbar(self.lc_2.T, self.lc_2.Y, self.lc_2.E, fmt='none',\n                  **series_args_2\n                  )\n\n    series_args_1.pop('capsize'), series_args_2.pop('capsize')\n    axis.scatter(self.lc_1.T, self.lc_1.Y,\n                 **(series_args_1 | {'s': 3, 'label': None})\n                 )\n    axis.scatter(self.lc_2.T, self.lc_2.Y,\n                 **(series_args_2 | {'s': 3, 'label': None})\n                 )\n\n    if show: plt.show()\n    return axis.get_figure()\n</code></pre>"},{"location":"mocks/#litmus.mocks.mock_cadence","title":"<code>mock_cadence(maxtime, seed: int = 0, cadence: float = 7, cadence_var: float = 1, season: float = 180, season_var: float = 14, N: int = 1024)</code>","text":"<p>Returns time series X values for a mock signal</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Seed for randomization</p> <code>0</code> <code>maxtime</code> <p>Length of observation window (default 180 days)</p> required <code>cadence</code> <code>float</code> <p>Average cadence of observations</p> <code>7</code> <code>cadence_var</code> <code>float</code> <p>Standard deviation of the cadence</p> <code>1</code> <code>season</code> <code>float</code> <p>Average length of the observation season (default 180 days)</p> <code>180</code> <code>season_var</code> <code>float</code> <p>Standard deviation of the season length (default 14 days)</p> <code>14</code> <code>N</code> <code>int</code> <p>Number of observations used prior to trimming. This is auto-tuned and is deprecated  returns as array of sample times</p> <code>1024</code> Source code in <code>litmus/mocks.py</code> <pre><code>def mock_cadence(maxtime, seed: int = 0, cadence: float = 7, cadence_var: float = 1, season: float = 180,\n                 season_var: float = 14, N: int = 1024):\n    \"\"\"\n    Returns time series X values for a mock signal\n    :param seed: Seed for randomization\n    :param maxtime: Length of observation window (default 180 days)\n    :param cadence: Average cadence of observations\n    :param cadence_var: Standard deviation of the cadence\n    :param season: Average length of the observation season (default 180 days)\n    :param season_var: Standard deviation of the season length (default 14 days)\n    :param N: Number of observations used prior to trimming. This is auto-tuned and is deprecated\n\n    returns as array of sample times\n    \"\"\"\n\n    np.random.seed(seed)\n\n    assert N&gt;0, \"Invalid N. Must be &lt;=0\"\n\n    # Generate Measurements\n    while True:\n        diffs = np.random.randn(N) * cadence_var / np.sqrt(2) + cadence\n        T = np.cumsum(diffs)\n        if T.max() &lt;= maxtime:\n            N *= 2\n        else:\n            break\n    T = T[np.where((T &lt; (maxtime * 2)))[0]]\n    T += np.random.randn(len(T)) * cadence_var / np.sqrt(2)\n\n    # Make windowing function\n    if season is not None and season != 0:\n\n        no_seasons = int(maxtime / season)\n        window = np.zeros(len(T))\n        for n in range(no_seasons):\n            if n % 2 == 0: continue\n            tick = np.tanh((T - season * n) / season_var)\n            tick -= np.tanh((T - season * (n + 1)) / season_var)\n            tick /= 2\n            window += tick\n\n        R = np.random.rand(len(window))\n\n        T = T[np.where((R &lt; window) * (T &lt; maxtime))[0]]\n    else:\n        T = T[np.where(T &lt; maxtime)[0]]\n\n    return (T)\n</code></pre>"},{"location":"mocks/#litmus.mocks.subsample","title":"<code>subsample(T, Y, Tsample) -&gt; ArrayN</code>","text":"<p>Linearly interpolates between X and Y and returns interped Y's at positions Xsample</p> Source code in <code>litmus/mocks.py</code> <pre><code>def subsample(T, Y, Tsample) -&gt; ArrayN:\n    \"\"\"\n    Linearly interpolates between X and Y and returns interped Y's at positions Xsample\n    \"\"\"\n    out = np.interp(Tsample, T, Y)\n    return (out)\n</code></pre>"},{"location":"mocks/#litmus.mocks.outly","title":"<code>outly(Y, q) -&gt; ArrayN</code>","text":"<p>Returns a copy of Y with fraction 'q' elements replaced with unit - normally distributed outliers</p> Source code in <code>litmus/mocks.py</code> <pre><code>def outly(Y, q) -&gt; ArrayN:\n    \"\"\"\n    Returns a copy of Y with fraction 'q' elements replaced with\n    unit - normally distributed outliers\n    \"\"\"\n    I = np.random.rand(len(Y)) &lt; q\n    Y[I] = np.random.randn() * len(I)\n    return (Y)\n</code></pre>"},{"location":"mocks/#litmus.mocks.gp_realization","title":"<code>gp_realization(T, err: Union[float, ArrayN] = 0.0, tau: float = 400.0, basekernel: tinygp.kernels.quasisep = tinygp.kernels.quasisep.Exp, seed=None) -&gt; lightcurve</code>","text":"<p>Generates a gaussian process at times T and errors err</p> <p>Parameters:</p> Name Type Description Default <code>T</code> <p>Time of observations</p> required <code>err</code> <code>Union[float, ArrayN]</code> <p>Measurements uncertainty at observations. Must be float or array of same length as T</p> <code>0.0</code> <code>tau</code> <code>float</code> <p>Timescale of the kernel</p> <code>400.0</code> <code>basekernel</code> <code>quasisep</code> <p>Kernel of the GP. Any tinyGP quasisep kernel</p> <code>Exp</code> <code>seed</code> <p>Returns as lightcurve object</p> <code>None</code> Source code in <code>litmus/mocks.py</code> <pre><code>def gp_realization(T, err: Union[float, ArrayN] = 0.0, tau: float = 400.0,\n                   basekernel: tinygp.kernels.quasisep = tinygp.kernels.quasisep.Exp,\n                   seed=None) -&gt; lightcurve:\n    '''\n    Generates a gaussian process at times T and errors err\n\n    :param T: Time of observations\n    :param err: Measurements uncertainty at observations. Must be float or array of same length as T\n    :param tau: Timescale of the kernel\n    :param basekernel: Kernel of the GP. Any tinyGP quasisep kernel\n    :param seed:\n\n    Returns as lightcurve object\n    '''\n    if seed is None: seed = randint()\n\n    # -----------------\n    # Generate errors\n    N = len(T)\n    if isiter(err):\n        E = err\n    else:\n        E = np.random.randn(N) * np.sqrt(err) + err\n    E = abs(E)\n\n    gp = GaussianProcess(basekernel(scale=tau), T)\n    Y = gp.sample(jax.random.PRNGKey(seed))\n\n    return (lightcurve(T=T, Y=Y, E=E))\n</code></pre>"},{"location":"mocks/#litmus.mocks.determ_gen","title":"<code>determ_gen(self, seed=0) -&gt; (ArrayN, ArrayN)</code>","text":"<p>Replaces the GP generation for the mock_A example to replace it with a nice gaussian curve</p> Source code in <code>litmus/mocks.py</code> <pre><code>def determ_gen(self, seed=0) -&gt; (ArrayN, ArrayN):\n    \"\"\"\n    Replaces the GP generation for the mock_A example to replace it with a nice gaussian curve\n    \"\"\"\n    f = lambda x: np.exp(-((x - 1000) / 2 / (64)) ** 2 / 2)\n    X = np.linspace(0.0, self.maxtime + self.lag * 2, self.N)\n    Y = f(X)\n    self.lc = lightcurve(X, Y).trimmed_copy(Tmin=0, Tmax=self.maxtime)\n    return (X, Y)\n</code></pre>"},{"location":"models/","title":"<code>litmus.models</code>","text":"<p>Contains NumPyro generative models.</p> <p>HM 24</p>"},{"location":"models/#litmus.models.lightcurve","title":"<code>lightcurve(T, Y, E=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>A wrapper class for lightcurves. Construct /w array-like inputs for time, signal and error (optional) like:    lightcurve(T, Y, E) or:     lightcurve(T, Y) Which yields E=0 for all {T,Y}</p> <p>Supports array-like addition and float-like addition / multiplication</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def __init__(self, T, Y, E=None):\n    self.T = np.array(T, dtype=np.float64)\n    self.Y = np.array(Y, dtype=np.float64)\n    if E is None:\n        self.E = np.zeros_like(T)\n    else:\n        self.E = E\n\n    self._data = np.vstack(self.values()).T\n\n    self._norm_mean, self._norm_amp = 0.0, 1.0\n    self.normalized = False\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.keys","title":"<code>keys() -&gt; [str, str, str]</code>","text":"<p>Returns the string-like names of the lightcurve's attributes</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def keys(self) -&gt; [str, str, str]:\n    \"\"\"\n    Returns the string-like names of the lightcurve's attributes\n    \"\"\"\n    return [\"T\", \"Y\", \"E\"]\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.values","title":"<code>values() -&gt; (ArrayN, ArrayN, ArrayN)</code>","text":"<p>Returns the lightcurves' value series' in the order of keys</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def values(self) -&gt; (ArrayN, ArrayN, ArrayN):\n    \"\"\"\n    Returns the lightcurves' value series' in the order of keys\n    \"\"\"\n    return [self[key] for key in self.keys()]\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.normalize","title":"<code>normalize() -&gt; Self</code>","text":"<p>Esimates the mean and amplitude of the lighturve assuming uncorrelated measurements Returns a lightcurve object with this normalization</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def normalize(self) -&gt; Self:\n    \"\"\"\n    Esimates the mean and amplitude of the lighturve assuming uncorrelated measurements\n    Returns a lightcurve object with this normalization\n    \"\"\"\n\n    if self.normalized: return self\n\n    # Check if have errorbars\n    no_errs = False\n    E = self.E\n    if max(E)== 0:\n        no_errs = True\n        E = np.ones_like(self.E)\n\n    # Get initial guess assuming no scatter\n    w = E ** -2\n    mean0 = np.average(self.Y, weights=w)\n    var0 = np.average((self.Y - mean0) ** 2, weights=w)\n\n    if no_errs:\n        meanbest, varbest = mean0, var0\n    else:\n        L = lambda X: ((self.Y - X[0]) ** 2 / (self.E ** 2 + X[1]) + np.log(self.E ** 2 + X[1])).sum()\n        meanbest, varbest = optimize.minimize(L, np.array([mean0, var0]), method='Nelder-Mead').x\n\n    # Make and return copy\n    out = copy(self)\n    out -= meanbest\n    out /= np.sqrt(varbest)\n\n    # If any errors, revert to simple estiamte\n    if np.any(np.isnan(out._data)):\n        meanbest, varbest = mean0, var0\n        out = copy(self)\n        out -= meanbest\n        out /= np.sqrt(varbest)\n\n    # Store normalizing values for later\n    out._norm_mean = meanbest\n    out._norm_amp = np.sqrt(varbest)\n\n    out.normalized = True\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.unnormalize","title":"<code>unnormalize() -&gt; Self</code>","text":"<p>Reverses the effects of lightcurve.normalize(). Returns a lightcurve object with mean and amplitude prior to normalize()</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def unnormalize(self) -&gt; Self:\n    \"\"\"\n    Reverses the effects of lightcurve.normalize().\n    Returns a lightcurve object with mean and amplitude prior to normalize()\n    \"\"\"\n    out = copy(self)\n    out *= self._norm_amp\n    out += self._norm_mean\n    out._norm_amp = 1.0\n    out._norm_mean = 0.0\n    out.normalized = False\n    return out\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.delayed_copy","title":"<code>delayed_copy(lag=0.0, Tmin=None, Tmax=None) -&gt; Self</code>","text":"<p>Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax] and offset by lag</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def delayed_copy(self, lag=0.0, Tmin=None, Tmax=None) -&gt; Self:\n    \"\"\"\n    Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax] and offset by lag\n    \"\"\"\n    if Tmin is None: Tmin = self.T.min()\n    if Tmax is None: Tmax = self.T.max()\n    I = np.where((self.T + lag &gt; Tmin) * (self.T + lag &lt; Tmax))[0]\n\n    return (lightcurve(T=self.T[I] + lag,\n                       Y=self.Y[I],\n                       E=self.E[I]\n                       ))\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.trimmed_copy","title":"<code>trimmed_copy(Tmin=None, Tmax=None) -&gt; Self</code>","text":"<p>Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax]</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def trimmed_copy(self, Tmin=None, Tmax=None) -&gt; Self:\n    \"\"\"\n    Returns a copy subsampled to only datapoints in the domain T in [Tmin,Tmax]\n    \"\"\"\n    return self.delayed_copy(0, Tmin, Tmax)\n</code></pre>"},{"location":"models/#litmus.models.lightcurve.plot","title":"<code>plot(axis=None, show=True, **kwargs) -&gt; None</code>","text":"<p>Plots an errorbar series to a matplotlib axis. If show=True, will plt.show() after plotting. If axis is None, will create a new figure. Pass in any plotting kwargs for plt.errorbar at **kwargs</p> Source code in <code>litmus/lightcurve.py</code> <pre><code>def plot(self, axis=None, show=True, **kwargs) -&gt; None:\n    \"\"\"\n    Plots an errorbar series to a matplotlib axis.\n    If show=True, will plt.show() after plotting.\n    If axis is None, will create a new figure.\n    Pass in any plotting kwargs for plt.errorbar at **kwargs\n    \"\"\"\n    if axis is None:\n        plt.figure()\n        axis = plt.gca()\n        axis.set_xlabel(\"T\")\n        axis.set_Ylabel(\"Y\")\n    axis.errorbar(self.T, self.Y, self.E, fmt='none', **kwargs)\n\n    if show: plt.show()\n</code></pre>"},{"location":"models/#litmus.models.Multiband","title":"<code>Multiband</code>","text":"<p>               Bases: <code>Wrapper</code></p> <p>Multi-band GP kernel that knows how to scale GP to output amplitudes</p>"},{"location":"models/#litmus.models.Multiband.coord_to_sortable","title":"<code>coord_to_sortable(Y) -&gt; float</code>","text":"<p>Extracts the time value from the (time,band) coordinate so the GP can interpret the ordering of points in multiple bands</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def coord_to_sortable(self, Y) -&gt; float:\n    \"\"\"\n    Extracts the time value from the (time,band) coordinate so the GP can interpret the ordering of points\n    in multiple bands\n    \"\"\"\n    t, band = Y\n    return t\n</code></pre>"},{"location":"models/#litmus.models.Multiband.observation_model","title":"<code>observation_model(Y) -&gt; float</code>","text":"<p>Scales the prediction for each band by their respective band amplitude in the predicted model</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def observation_model(self, Y) -&gt; float:\n    \"\"\"\n    Scales the prediction for each band by their respective band amplitude in the predicted model\n    \"\"\"\n    t, band = Y\n    return self.amplitudes[band] * self.kernel.observation_model(t)\n</code></pre>"},{"location":"models/#litmus.models.stats_model","title":"<code>stats_model(prior_ranges=None, out_stream=sys.stdout, err_stream=sys.stderr, verbose=True, debug=True)</code>","text":"<p>               Bases: <code>logger</code></p> <p>Base class for bayesian generative models. Includes a series of utilities for evaluating likelihoods, gradients etc., as well as various</p> <p>On init, takes dict `prior_ranges' of the uniform boundaries of the parameter priors, or a single (float/int) value if the value is fixed, e.g. stats_model(prior_ranges = {     'lag': [0, 1000],     'amp': 1.0     }) Also takes logging arg from the litmus.logging.logger object.</p> Source code in <code>litmus/models.py</code> <pre><code>def __init__(self, prior_ranges=None,\n             out_stream=sys.stdout,\n             err_stream=sys.stderr,\n             verbose=True,\n             debug=True,\n             ):\n\n    logger.__init__(self, out_stream=out_stream, err_stream=err_stream, verbose=verbose, debug=debug)\n\n    self._protected_keys = []\n\n    self.out_stream = out_stream\n    self.err_stream = err_stream\n\n    # Setting prior boundaries\n    if not hasattr(self, \"_default_prior_ranges\"):\n        self._default_prior_ranges = {\n            'lag': _default_config['lag'],\n        }\n\n    self.prior_ranges = {} | self._default_prior_ranges  # Create empty priors\n    self.prior_volume = 1.0\n\n    # Update with args\n    self.set_priors(self._default_prior_ranges | prior_ranges) if prior_ranges is not None else self.set_priors(\n        self._default_prior_ranges)\n\n    self.debug = False\n\n    self.name = type(self).__name__\n\n    self._prep_funcs()\n</code></pre>"},{"location":"models/#litmus.models.stats_model.set_priors","title":"<code>set_priors(prior_ranges: dict) -&gt; None</code>","text":"<p>Sets the stats model prior ranges for uniform priors. Does some sanity checking to avoid negative priors e.g. stats_model(prior_ranges = {     'lag': [0, 1000],     'amp': 1.0     })</p> Source code in <code>litmus/models.py</code> <pre><code>def set_priors(self, prior_ranges: dict) -&gt; None:\n    '''\n    Sets the stats model prior ranges for uniform priors. Does some sanity checking to avoid negative priors\n    e.g.\n    stats_model(prior_ranges = {\n        'lag': [0, 1000],\n        'amp': 1.0\n        })\n    '''\n\n    badkeys = [key for key in prior_ranges.keys() if key not in self._default_prior_ranges.keys()]\n\n    for key, val in zip(prior_ranges.keys(), prior_ranges.values()):\n        if key in badkeys:\n            continue\n\n        if isiter(val):\n            a, b = val\n        else:\n            try:\n                a, b = val, val\n            except:\n                raise \"Bad input shape in set_priors for key %s\" % key  # todo - make this go to std.err\n\n        self.prior_ranges[key] = [float(a), float(b)]\n\n    # Calc and set prior volume\n    # Todo - Make this more general. Revisit if we separate likelihood + prior\n    prior_volume = 1.0\n    for key in self.prior_ranges:\n        a, b = self.prior_ranges[key]\n        if b != a:\n            prior_volume *= b - a\n    self.prior_volume = prior_volume\n\n    self._prep_funcs()\n\n    return\n</code></pre>"},{"location":"models/#litmus.models.stats_model.prior","title":"<code>prior() -&gt; [float]</code>","text":"<p>A NumPyro callable prior Returns the values of the parameters</p> Source code in <code>litmus/models.py</code> <pre><code>def prior(self) -&gt; [float, ]:\n    '''\n    A NumPyro callable prior\n    Returns the values of the parameters\n    '''\n    lag = numpyro.sample('lag', dist.Uniform(self.prior_ranges['lag'][0], self.prior_ranges['lag'][1]))\n    return (lag)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.model_function","title":"<code>model_function(data)</code>","text":"<p>A NumPyro callable function. Does not return</p> Source code in <code>litmus/models.py</code> <pre><code>def model_function(self, data):\n    '''\n    A NumPyro callable function. Does not return\n    '''\n    lag = self.prior()\n</code></pre>"},{"location":"models/#litmus.models.stats_model.lc_to_data","title":"<code>lc_to_data(lc_1: lightcurve, lc_2: lightcurve) -&gt; dict</code>","text":"<p>Converts light-curves into the format required for the model. For most models this will return as some sort of sorted dictionary</p> <p>Parameters:</p> Name Type Description Default <code>lc_1</code> <code>lightcurve</code> <p>First lightcurve object</p> required <code>lc_2</code> <code>lightcurve</code> <p>Second lightcurve object</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Varies from model to model, by default will be a keyed dict: {'T': Time values of observations series, 'Y': Signal strength values of observations series, 'E': Uncertainty values of values in Y, 'bands': int array identifying which lightcurve (0,1) that the observations belong to }</p> Source code in <code>litmus/models.py</code> <pre><code>def lc_to_data(self, lc_1: lightcurve, lc_2: lightcurve) -&gt; dict:\n    '''\n    Converts light-curves into the format required for the model. For most models this will return as some sort\n    of sorted dictionary\n    :param lc_1: First lightcurve object\n    :param lc_2: Second lightcurve object\n    :return: Varies from model to model, by default will be a keyed dict:\n        {'T': Time values of observations series,\n         'Y': Signal strength values of observations series,\n         'E': Uncertainty values of values in Y,\n         'bands': int array identifying which lightcurve (0,1) that the observations belong to\n        }\n    '''\n\n    T = jnp.array([*lc_1.T, *lc_2.T])\n    Y = jnp.array([*lc_1.Y, *lc_2.Y])\n    E = jnp.array([*lc_1.E, *lc_2.E])\n    bands = jnp.array([*np.zeros(lc_1.N), *np.ones(lc_2.N)]).astype(int)\n\n    I = T.argsort()\n\n    T, Y, E, bands = T[I], Y[I], E[I], bands[I]\n\n    data = {'T': T,\n            'Y': Y,\n            'E': E,\n            'bands': bands\n            }\n\n    return (data)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.to_uncon","title":"<code>to_uncon(params) -&gt; dict[str, float]</code>","text":"<p>Converts model parametes from \"real\" constrained domain values into HMC friendly unconstrained values. Inputs and outputs as keyed dict.</p> Source code in <code>litmus/models.py</code> <pre><code>def to_uncon(self, params) -&gt; dict[str, float]:\n    '''\n    Converts model parametes from \"real\" constrained domain values into HMC friendly unconstrained values.\n    Inputs and outputs as keyed dict.\n    '''\n    out = numpyro.infer.util.unconstrain_fn(self.prior, params=params, model_args=(), model_kwargs={})\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.to_con","title":"<code>to_con(params) -&gt; dict[str, float]</code>","text":"<p>Converts model parametes back into \"real\" constrained domain values. Inputs and outputs as keyed dict.</p> Source code in <code>litmus/models.py</code> <pre><code>def to_con(self, params) -&gt; dict[str, float]:\n    '''\n    Converts model parametes back into \"real\" constrained domain values.\n    Inputs and outputs as keyed dict.\n    '''\n    out = numpyro.infer.util.constrain_fn(self.prior, params=params, model_args=(), model_kwargs={})\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.uncon_grad","title":"<code>uncon_grad(params) -&gt; float</code>","text":"<p>Returns the log of det(Jac) by evaluating pi(x) and pi'(x'). Used for correcting integral elements between constrained and unconstrained space</p> Source code in <code>litmus/models.py</code> <pre><code>def uncon_grad(self, params) -&gt; float:\n    '''\n    Returns the log of det(Jac) by evaluating pi(x) and pi'(x').\n    Used for correcting integral elements between constrained and unconstrained space\n    '''\n    con_dens = numpyro.infer.util.log_density(self.prior, (), {}, params)[0]\n\n    up = self.to_uncon(params)\n    uncon_dens = -numpyro.infer.util.potential_energy(self.prior, (), {}, up)\n    out = con_dens - uncon_dens\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.uncon_grad_lag","title":"<code>uncon_grad_lag(params) -&gt; float</code>","text":"<p>Returns the log-jacobian correction for the constrained / unconstrained correction for the lag parameter Assumes a uniform distribution for the lag prior</p> Source code in <code>litmus/models.py</code> <pre><code>def uncon_grad_lag(self, params) -&gt; float:\n    '''\n    Returns the log-jacobian correction for the constrained / unconstrained correction for the lag parameter\n    Assumes a uniform distribution for the lag prior\n    '''\n\n    from numpyro.infer.util import transform_fn\n\n    if 'lag' not in self.paramnames(): return 0\n    if np.ptp(self.prior_ranges['lag']) == 0: return 0\n\n    lagdist = dist.Uniform(*self.prior_ranges['lag'])\n    lag_con = params['lag']\n\n    transforms = {\"lag\": numpyro.distributions.biject_to(lagdist.support)}\n\n    def tform(x):\n        out = transform_fn(transforms, params | {'lag': x}, invert=True)['lag']\n        return (out)\n\n    tform = jax.grad(tform)\n    out = np.log(abs(tform(lag_con)))\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.paramnames","title":"<code>paramnames() -&gt; [str]</code>","text":"<p>Returns the names of all model parameters. Purely for brevity of code. Returns as list</p> Source code in <code>litmus/models.py</code> <pre><code>def paramnames(self) -&gt; [str]:\n    '''\n    Returns the names of all model parameters. Purely for brevity of code.\n    Returns as list\n    '''\n    return (list(self.prior_ranges.keys()))\n</code></pre>"},{"location":"models/#litmus.models.stats_model.fixed_params","title":"<code>fixed_params() -&gt; [str]</code>","text":"<p>Returns the names of all fixed model parameters. Purely for brevity. Returns as list</p> Source code in <code>litmus/models.py</code> <pre><code>def fixed_params(self) -&gt; [str]:\n    '''\n    Returns the names of all fixed model parameters. Purely for brevity.\n    Returns as list\n    '''\n    is_fixed = {key: np.ptp(self.prior_ranges[key]) == 0 for key in self.prior_ranges.keys()}\n    out = [key for key in is_fixed.keys() if is_fixed[key]]\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.free_params","title":"<code>free_params() -&gt; [str]</code>","text":"<p>Returns the names of all free model parameters. Purely for brevity of code. Returns as list</p> Source code in <code>litmus/models.py</code> <pre><code>def free_params(self) -&gt; [str]:\n    '''\n    Returns the names of all free model parameters. Purely for brevity of code.\n    Returns as list\n    '''\n    is_fixed = {key: np.ptp(self.prior_ranges[key]) == 0 for key in self.prior_ranges.keys()}\n    out = [key for key in is_fixed.keys() if not is_fixed[key]]\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.dim","title":"<code>dim() -&gt; int</code>","text":"<p>Quick and easy call for the number of model parameters. Returns as int</p> Source code in <code>litmus/models.py</code> <pre><code>def dim(self) -&gt; int:\n    '''\n    Quick and easy call for the number of model parameters.\n    Returns as int\n    '''\n    return len(self.free_params())\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density","title":"<code>log_density(params, data, use_vmap=False) -&gt; ArrayN</code>","text":"<p>Returns the log density of the joint distribution at some constrained space position 'params' and conditioned on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as array of floats use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density(self, params, data, use_vmap=False) -&gt; ArrayN:\n    \"\"\"\n    Returns the log density of the joint distribution at some constrained space position 'params' and conditioned\n    on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of\n    parameter values or a key dict of arrays of values.\n    Returns as array of floats\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter_dict(params):\n        N = dict_dim(params)[1]\n        out = np.zeros(N)\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            out[i] = self._log_density_jit(p, data)\n    else:\n        out = np.array([self._log_density_jit(params, data)])\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_likelihood","title":"<code>log_likelihood(params, data, use_vmap=False) -&gt; ArrayN</code>","text":"<p>Returns the log likelihood at some constrained space position 'params' and conditioned on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as array of floats use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_likelihood(self, params, data, use_vmap=False) -&gt; ArrayN:\n    \"\"\"\n    Returns the log likelihood at some constrained space position 'params' and conditioned\n    on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of\n    parameter values or a key dict of arrays of values.\n    Returns as array of floats\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n    if isiter_dict(params):\n        N = dict_dim(params)[1]\n        out = np.zeros(N)\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            out[i] = self._log_likelihood(p, data)\n    else:\n        out = self._log_likelihood(params, data)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density_uncon","title":"<code>log_density_uncon(params, data, use_vmap=False) -&gt; ArrayN</code>","text":"<p>Returns the log density of the joint distribution at some unconstrained space position 'params' and conditioned on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as array of floats use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density_uncon(self, params, data, use_vmap=False) -&gt; ArrayN:\n    \"\"\"\n    Returns the log density of the joint distribution at some unconstrained space position 'params' and conditioned\n    on some 'data'. data must match the output of the model's lc_to_data(), and params is either a keyed dict of\n    parameter values or a key dict of arrays of values.\n    Returns as array of floats\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter_dict(params):\n        N = dict_dim(params)[1]\n        out = np.zeros(N)\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            out[i] = self._log_density_uncon_jit(p, data)\n    else:\n        out = self._log_density_uncon_jit(params, data)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_prior","title":"<code>log_prior(params, data=None, use_vmap=False) -&gt; ArrayN</code>","text":"<p>Returns the log density of the prior  at some constrained space position 'params' Params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as array of floats use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_prior(self, params, data=None, use_vmap=False) -&gt; ArrayN:\n    \"\"\"\n    Returns the log density of the prior  at some constrained space position 'params'\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    Returns as array of floats\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter_dict(params):\n        N = dict_dim(params)[1]\n        out = np.zeros(N)\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            out[i] = self._log_prior_jit(p)\n    else:\n        out = self._log_prior_jit(params)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density_grad","title":"<code>log_density_grad(params, data, use_vmap=False, keys=None) -&gt; dict[str, float]</code>","text":"<p>Returns the gradient of the log density of the joint distribution at some constrained space position 'params', conditionded on some 'data' matching the format of the model's lc_to_data() output. Params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as keyed dict of grads along each axsi or keyed dict of array of similar values use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density_grad(self, params, data, use_vmap=False, keys=None) -&gt; dict[str, float]:\n    \"\"\"\n    Returns the gradient of the log density of the joint distribution at some constrained space position 'params',\n    conditionded on some 'data' matching the format of the model's lc_to_data() output.\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    Returns as keyed dict of grads along each axsi or keyed dict of array of similar values\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter_dict(params):\n        m, N = dict_dim(params)\n        out = {key: np.zeros([N]) for key in params.keys()}\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            grads = self._log_density_grad(p, data)\n            for key in params.keys():\n                out[key][i] = grads[key]\n    else:\n        out = self._log_density_grad(params, data)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density_uncon_grad","title":"<code>log_density_uncon_grad(params, data, use_vmap=False, keys=None, asdict=False) -&gt; float</code>","text":"<p>Returns the gradient of the log density of the joint distribution at some unconstrained space position 'params', conditionded on some 'data' matching the format of the model's lc_to_data() output. Params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as keyed dict of grads along each axsi or keyed dict of array of similar values use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density_uncon_grad(self, params, data, use_vmap=False, keys=None, asdict=False) -&gt; float:\n    \"\"\"\n    Returns the gradient of the log density of the joint distribution at some unconstrained space position 'params',\n    conditionded on some 'data' matching the format of the model's lc_to_data() output.\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    Returns as keyed dict of grads along each axsi or keyed dict of array of similar values\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter_dict(params):\n        m, N = dict_dim(params)\n        out = {key: np.zeros([N]) for key in params.keys()}\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            grads = self._log_density_uncon_grad(p, data)\n            for key in params.keys():\n                out[key][i] = grads[key]\n    else:\n        out = self._log_density_uncon_grad(params, data)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_prior_grad","title":"<code>log_prior_grad(params, data=None, use_vmap=False, keys=None) -&gt; dict[str, float]</code>","text":"<p>Returns the gradient of the log prior of the prior at some constrained space position 'params' Params is either a keyed dict of parameter values or a key dict of arrays of values. Returns as keyed dict of grads along each axsi or keyed dict of array of similar values use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_prior_grad(self, params, data=None, use_vmap=False, keys=None) -&gt; dict[str, float]:\n    \"\"\"\n    Returns the gradient of the log prior of the prior at some constrained space position 'params'\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    Returns as keyed dict of grads along each axsi or keyed dict of array of similar values\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if isiter(params):\n        m, N = dict_dim(params)\n        out = np.zeros(N)\n        for i in range(N):\n            p = {key: params[key][i] for key in params.keys()}\n            out[i, :] = self._log_prior_grad(p)\n    else:\n        out = self._log_prior_grad(params)\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density_hess","title":"<code>log_density_hess(params, data, use_vmap=False, keys=None) -&gt; ArrayNxMxM</code>","text":"<p>Returns the hessian matrix of the log joint distribution at some constrained space position 'params', conditioned on some 'data' matching the output of the model's lc_to_data() output. Params is either a keyed dict of parameter values or a key dict of arrays of values. parameter 'keys' is the params to slice and sort the hessian matrices. Returns in order / dimension: [num param sites, num keys, num keys] use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density_hess(self, params, data, use_vmap=False, keys=None) -&gt; ArrayNxMxM:\n    \"\"\"\n    Returns the hessian matrix of the log joint distribution at some constrained space position 'params',\n    conditioned on some 'data' matching the output of the model's lc_to_data() output.\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    parameter 'keys' is the params to slice and sort the hessian matrices.\n    Returns in order / dimension: [num param sites, num keys, num keys]\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if keys is None: keys = params.keys()\n\n    if isiter_dict(params):\n        m, N = dict_dim(params)\n        m = len(keys)\n        out = np.zeros([N, m, m])\n        for i in range(N):\n            p = {key: params[key][i] for key in keys}\n            hess_eval = self._log_density_hess(p, data)\n            for j, key1 in enumerate(keys):\n                for k, key2 in enumerate(keys):\n                    out[i, j, k] = hess_eval[key1][key2]\n    else:\n        m = len(keys)\n        out = np.zeros([m, m])\n        hess_eval = self._log_density_hess(params, data)\n        for j, key1 in enumerate(keys):\n            for k, key2 in enumerate(keys):\n                out[j, k] = hess_eval[key1][key2]\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_density_uncon_hess","title":"<code>log_density_uncon_hess(params, data, use_vmap=False, keys=None) -&gt; ArrayNxMxM</code>","text":"<p>Returns the hessian matrix of the log joint distribution at some unconstrained space position 'params', conditioned on some 'data' matching the output of the model's lc_to_data() output. Params is either a keyed dict of parameter values or a key dict of arrays of values. parameter 'keys' is the params to slice and sort the hessian matrices. Returns in order / dimension: [num param sites, num keys, num keys] use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_density_uncon_hess(self, params, data, use_vmap=False, keys=None) -&gt; ArrayNxMxM:\n    \"\"\"\n    Returns the hessian matrix of the log joint distribution at some unconstrained space position 'params',\n    conditioned on some 'data' matching the output of the model's lc_to_data() output.\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    parameter 'keys' is the params to slice and sort the hessian matrices.\n    Returns in order / dimension: [num param sites, num keys, num keys]\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if keys is None: keys = params.keys()\n\n    if isiter_dict(params):\n        m, N = dict_dim(params)\n        m = len(keys)\n        out = np.zeros([N, m, m])\n        for i in range(N):\n            p = {key: params[key][i] for key in keys}\n            hess_eval = self._log_density_uncon_hess(p, data)\n            for j, key1 in enumerate(keys):\n                for k, key2 in enumerate(keys):\n                    out[i, j, k] = hess_eval[key1][key2]\n    else:\n        m = len(keys)\n        out = np.zeros([m, m])\n        hess_eval = self._log_density_uncon_hess(params, data)\n        for j, key1 in enumerate(keys):\n            for k, key2 in enumerate(keys):\n                out[j, k] = hess_eval[key1][key2]\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.log_prior_hess","title":"<code>log_prior_hess(params, data=None, use_vmap=False, keys=None) -&gt; ArrayNxMxM</code>","text":"<p>Returns the hessian matrix of the log prior of the prior at some constrained space position 'params' Params is either a keyed dict of parameter values or a key dict of arrays of values. parameter 'keys' is the params to slice and sort the hessian matrices. Returns in order / dimension: [num param sites, num keys, num keys] use_vmap currently not implemented with no side effect</p> Source code in <code>litmus/models.py</code> <pre><code>def log_prior_hess(self, params, data=None, use_vmap=False, keys=None) -&gt; ArrayNxMxM:\n    \"\"\"\n    Returns the hessian matrix of the log prior of the prior at some constrained space position 'params'\n    Params is either a keyed dict of parameter values or a key dict of arrays of values.\n    parameter 'keys' is the params to slice and sort the hessian matrices.\n    Returns in order / dimension: [num param sites, num keys, num keys]\n    use_vmap currently not implemented with no side effect\n    \"\"\"\n\n    if keys is None: keys = params.keys()\n\n    if isiter_dict(params):\n        m, N = dict_dim(params)\n        m = len(keys)\n        out = np.zeros([N, m, m])\n        for i in range(N):\n            p = {key: params[key][i] for key in keys}\n            hess_eval = self._log_prior_hess(p)\n            for j, key1 in enumerate(keys):\n                for k, key2 in enumerate(keys):\n                    out[i, j, k] = hess_eval[key1][key2]\n    else:\n        m = len(keys)\n        out = np.zeros([m, m])\n        hess_eval = self._log_prior_hess(params)\n        for j, key1 in enumerate(keys):\n            for k, key2 in enumerate(keys):\n                out[j, k] = hess_eval[key1][key2]\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.scan","title":"<code>scan(start_params, data, optim_params=None, use_vmap=False, optim_kwargs={}, precondition='diag') -&gt; dict[str, float]</code>","text":"<p>Beginning at position 'start_params', optimize parameters in 'optim_params' to find maximum.</p> <p>optim_kwargs will overwrite defaults and be passed directly to jaxopt.BFGS object</p> <p>Currently using jaxopt with optim_kwargs:     'stepsize': 0.0,     'min_stepsize': 1E-5,     'increase_factor': 1.2,     'maxiter': 1024,     'linesearch': 'backtracking',     'verbose': False,</p> Source code in <code>litmus/models.py</code> <pre><code>def scan(self, start_params, data, optim_params=None, use_vmap=False, optim_kwargs={}, precondition='diag') -&gt; dict[\n    str, float]:\n    '''\n    Beginning at position 'start_params', optimize parameters in 'optim_params' to find maximum.\n\n    optim_kwargs will overwrite defaults and be passed directly to jaxopt.BFGS object\n\n    Currently using jaxopt with optim_kwargs:\n        'stepsize': 0.0,\n        'min_stepsize': 1E-5,\n        'increase_factor': 1.2,\n        'maxiter': 1024,\n        'linesearch': 'backtracking',\n        'verbose': False,\n    '''\n\n    optimizer_args = {\n        'stepsize': 0.0,\n        'min_stepsize': 1E-5,\n        'increase_factor': 1.2,\n        'maxiter': 256,\n        'linesearch': 'backtracking',\n        'verbose': False,\n    }\n\n    optimizer_args |= optim_kwargs\n\n    # Convert to unconstrained domain\n    start_params_uncon = self.to_uncon(start_params)\n\n    if optim_params is None:\n        optim_params = [name for name in self.paramnames() if\n                        self.prior_ranges[name][0] != self.prior_ranges[name][1]\n                        ]\n    if len(optim_params) == 0: return start_params\n\n    # Get all split into fixed and free params\n    x0, y0 = dict_split(start_params_uncon, optim_params)\n    x0 = dict_pack(x0)\n\n    # -------------------------------------\n    # Build preconditioning matrix\n    H = self.log_density_uncon_hess(start_params_uncon, data, keys=optim_params)\n    H *= -1\n    if precondition == \"cholesky\":\n        H = np.linalg.cholesky(np.linalg.inv(H))\n        Hinv = np.linalg.inv(H)\n\n    elif precondition == \"eig\":\n        D, P = np.linalg.eig(H)\n        if D.min() &lt; 0:\n            D[np.where(D &lt; 0)[0].min()] = 1.0\n        D, P = D.astype(float), P.astype(float)\n        D **= -0.5\n\n        H = np.dot(P, np.dot(np.diag(D), P.T))\n        Hinv = np.dot(P, np.dot(np.diag(D ** -1), P.T))\n\n    elif precondition == \"half-eig\":\n        D, P = np.linalg.eig(H)\n        if D.min() &lt; 0:\n            D[np.where(D &lt; 0)[0].min()] = 1.0\n        D, P = D.astype(float), P.astype(float)\n        D **= -0.5\n\n        H = np.dot(P, np.diag(D))\n        Hinv = np.dot(np.diag(D ** -1), P.T)\n\n    elif precondition == \"diag\":\n        D = np.diag(H) ** -0.5\n        D = np.where(D &gt; 0, D, 1.0)\n        H = np.diag(D)\n        Hinv = np.diag(1 / D)\n\n    else:\n        H = np.eye(len(optim_params))\n        Hinv = np.eye(len(optim_params))\n\n    if self.debug:\n        print(\"Scaling matrix:\")\n        print(H)\n        print(\"Inverse Scaling matrix:\")\n        print(Hinv)\n\n    '''\n    optfunc = pack_function(self._log_density_uncon,\n                            packed_keys=optim_params,\n                            fixed_values=y0,\n                            invert=True,\n                            H=H,\n                            d0=start_params_uncon\n                            )\n    '''\n\n    def optfunc(X):\n        Y = jnp.dot(H, X) + x0\n        params = y0 | {key: Y[i] for i, key in enumerate(optim_params)}\n        out = - self._log_density_uncon(params, data)\n        return (out)\n\n    X0 = np.zeros_like(x0)\n\n    if self.debug:\n        print(\"At initial uncon position\", x0, \"with keys\", optim_params, \"eval for optfunc is\",\n              optfunc(X0))\n\n    assert not np.isinf(optfunc(np.zeros_like(x0))), \"Something wrong with start positions in scan!\"\n\n    # =====================\n    # Jaxopt Work\n\n    # Build the optimizer\n    solver = jaxopt.BFGS(fun=optfunc,\n                         value_and_grad=False,\n                         jit=True,\n                         **optimizer_args\n                         )\n\n    # Debug safety check to see if something's breaking\n\n    if self.debug:\n        print(\"Creating and testing solver...\")\n        try:\n            init_state = solver.init_state(X0)\n            with suppress_stdout():  # TODO - Supressing of warnings, should be patched in newest jaxopt\n                solver.update(params=X0, state=init_state)\n            print(\"Jaxopt solver created and running fine\")\n        except:\n            print(\"Something went wrong in when making the jaxopt optimizer. Double check your inputs.\")\n\n    with suppress_stdout():  # TODO - Supressing of warnings, should be patched in newest jaxopt\n        sol, state = solver.run(init_params=X0)\n\n    out = np.dot(H, sol) + x0\n\n    # =====================\n    # Cleanup and return\n    if self.debug:\n        print(\"At final uncon position\", out, \"with keys\", optim_params, \"eval for optfunc is\",\n              optfunc(sol)\n              )\n\n    # Unpack the results to a dict\n    out = {key: out[i] for i, key in enumerate(optim_params)}\n    out = out | y0  # Adjoin the fixed values\n\n    # Convert back to constrained domain\n    out = self.to_con(out)\n\n    out = {key: float(val) for key, val in zip(out.keys(), out.values())}\n\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.laplace_log_evidence","title":"<code>laplace_log_evidence(params, data, integrate_axes=None, use_vmap=False, constrained=False) -&gt; float</code>","text":"<p>At some point 'params' in parameter space, gets the hessian in unconstrained space and uses to estimate the model evidence</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <p>Keyed dict with params in constrained / unconstrained parameter space</p> required <code>data</code> <p>data for model.</p> required <code>integrate_axes</code> <p>Which axes to perform laplace approx for. If none, use all</p> <code>None</code> <code>use_vmap</code> <p>Placeholder. If true, perform in parallel for many sources</p> <code>False</code> <code>constrained</code> <p>If true, perform laplace approx in constrained domain. Default to false</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> Source code in <code>litmus/models.py</code> <pre><code>def laplace_log_evidence(self, params, data, integrate_axes=None, use_vmap=False, constrained=False) -&gt; float:\n    '''\n    At some point 'params' in parameter space, gets the hessian in unconstrained space and uses to estimate the\n    model evidence\n    :param params: Keyed dict with params in constrained / unconstrained parameter space\n    :param data: data for model.\n    :param integrate_axes: Which axes to perform laplace approx for. If none, use all\n    :param use_vmap: Placeholder. If true, perform in parallel for many sources\n    :param constrained: If true, perform laplace approx in constrained domain. Default to false\n    :return:\n    '''\n\n    if self.debug: print(\"-------------\")\n    if self.debug: print(\"Laplace Evidence eval\")\n\n    if self.debug: print(\"Constrained params are:\")\n    if self.debug: print(params)\n\n    if integrate_axes is None:\n        integrate_axes = self.paramnames()\n\n    # Get 'height' and curvature of Gaussian\n    if not constrained:\n        uncon_params = self.to_uncon(params)\n\n        if self.debug: print(\"Un-Constrained params are:\")\n        if self.debug: print(uncon_params)\n\n        log_height = self.log_density_uncon(uncon_params, data)\n        hess = self.log_density_uncon_hess(uncon_params, data, keys=integrate_axes)\n    else:\n        log_height = self.log_density(params, data)\n        hess = self.log_density_hess(params, data, keys=integrate_axes)\n\n    dethess = np.linalg.det(-hess)\n\n    if self.debug: print(\"With determinant:\")\n    if self.debug: print(dethess)\n\n    if self.debug: print(\"And log height: %.2f...\" % log_height)\n\n    D = len(integrate_axes)\n    out = np.log(2 * np.pi) * (D / 2) - np.log(dethess) / 2 + log_height\n\n    if self.debug: print(\"log-evidence is ~%.2f\" % out)\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.laplace_log_info","title":"<code>laplace_log_info(params, data, integrate_axes=None, use_vmap=False, constrained=False)</code>","text":"<p>At some point 'params' in parameter space, gets the hessian in unconstrained space and uses to estimate the model information relative to the prior</p>"},{"location":"models/#litmus.models.stats_model.laplace_log_info--todo-finish-documentation","title":"todo - finish documentation","text":"<p>Parameters:</p> Name Type Description Default <code>integrate_axes</code> <code>None</code> <code>data</code> required <code>params</code> required <code>use_vmap</code> <code>False</code> <code>constrained</code> <code>False</code> <p>Returns:</p> Type Description Source code in <code>litmus/models.py</code> <pre><code>def laplace_log_info(self, params, data, integrate_axes=None, use_vmap=False, constrained=False):\n    '''\n    At some point 'params' in parameter space, gets the hessian in unconstrained space and uses to estimate the\n    model information relative to the prior\n    # todo - finish documentation\n    :param integrate_axes:\n    :param data:\n    :param params:\n    :param use_vmap:\n    :param constrained:\n    :return:\n    '''\n\n    if integrate_axes is None:\n        integrate_axes = self.paramnames()\n\n    if not constrained:\n        uncon_params = self.to_uncon(params)\n\n        log_height = self.log_density_uncon(uncon_params, data)\n        hess = self.log_density_uncon_hess(uncon_params, data)\n    else:\n        log_height = self.log_density(params, data)\n        hess = self.log_density_hess(params, data)\n\n    I = np.where([key in integrate_axes for key in self.paramnames()])[0]\n\n    hess = hess[I, I]\n    if len(I) &gt; 1:\n        dethess = np.linalg.det(hess)\n    else:\n        dethess = hess\n\n    # todo - double check sign on the log term. Might be wrong\n    # todo - add case check for non-uniform priors.\n    D = len(integrate_axes)\n    out = -(np.log(2 * np.pi) + 1) * (D / 2) - np.log(-dethess) / 2 + np.log(self.prior_volume)\n    return out\n</code></pre>"},{"location":"models/#litmus.models.stats_model.prior_sample","title":"<code>prior_sample(num_samples: int = 1, seed: int = None) -&gt; dict</code>","text":"<p>Blind sampling from the prior without conditioning. Returns model parameters only</p> <p>Parameters:</p> Name Type Description Default <code>num_samples</code> <code>int</code> <p>Number of realizations to generate</p> <code>1</code> <code>seed</code> <code>int</code> <p>seed for random generation</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> Source code in <code>litmus/models.py</code> <pre><code>def prior_sample(self, num_samples: int = 1, seed: int = None) -&gt; dict:\n    '''\n    Blind sampling from the prior without conditioning. Returns model parameters only\n    :param num_samples: Number of realizations to generate\n    :param seed: seed for random generation\n    :return:\n    '''\n\n    if seed == None: seed = randint()\n\n    pred = numpyro.infer.Predictive(self.prior,\n                                    num_samples=num_samples,\n                                    return_sites=self.paramnames()\n                                    )\n\n    params = pred(rng_key=jax.random.PRNGKey(seed))\n\n    if num_samples == 1:\n        params = {key: params[key][0] for key in params.keys()}\n    return (params)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.realization","title":"<code>realization(data=None, num_samples: int = 1, seed: int = None)</code>","text":"<p>Generates realizations of the observables by blindly sampling from the prior :data: data to condition the lightcurve on</p> <p>Parameters:</p> Name Type Description Default <code>num_samples</code> <code>int</code> <p>Number of realizations to generate</p> <code>1</code> <p>Returns:</p> Type Description Source code in <code>litmus/models.py</code> <pre><code>def realization(self, data=None, num_samples: int = 1, seed: int = None):\n    '''\n    Generates realizations of the observables by blindly sampling from the prior\n    :data: data to condition the lightcurve on\n    :param num_samples: Number of realizations to generate\n    :return:\n    '''\n    if seed == None: seed = randint()\n\n    pred = numpyro.infer.Predictive(self.model_function,\n                                    num_samples=num_samples,\n                                    return_sites=None\n                                    )\n\n    params = pred(rng_key=jax.random.PRNGKey(seed), data=data)\n    return (params)\n</code></pre>"},{"location":"models/#litmus.models.stats_model.make_lightcurves","title":"<code>make_lightcurves(data, params: dict, Tpred, num_samples: int = 1) -&gt; (lightcurve, lightcurve)</code>","text":"<p>Returns lightcurves at time 'T' for 'parameters' conditioned on 'data' over <code>num_samples</code> draws from <code>params</code> Returns like (loc_1, loc_2, covar_1, covar_2)</p> Source code in <code>litmus/models.py</code> <pre><code>def make_lightcurves(self, data, params: dict, Tpred, num_samples: int = 1) -&gt; (lightcurve, lightcurve):\n    '''\n    Returns lightcurves at time 'T' for 'parameters' conditioned on 'data' over `num_samples` draws from `params`\n    Returns like (loc_1, loc_2, covar_1, covar_2)\n    '''\n\n    len_params = dict_dim(params)[1]\n    if num_samples &gt; len_params:\n        self.msg_err(\"Warning! Tried to call %i samples from only %i parameters in make_lightcurves\" % (\n            num_samples, len_params))\n\n    loc_1 = np.zeros_like(Tpred)\n    covar_1 = np.zeros([len(Tpred), len(Tpred)])\n    loc_2, covar_2 = loc_1.copy(), covar_1.copy()\n\n    if self._gen_lightcurve is stats_model._gen_lightcurve:\n        self.msg_err(\"Warning, called make_lightcurves on a stats_model that doesn't have implementation\")\n\n    if not isiter_dict(params):\n        loc_1, loc_2, covar_1, covar_2 = self.gen_lightcurve(data, params, jnp.array(Tpred))\n\n    else:\n        I = np.random.choice(range(len_params), num_samples, replace=True)\n        loc_1_all = np.tile(loc_1, (num_samples, 1)) * 0\n        loc_2_all = loc_1_all.copy()\n\n        for k, p_sample in enumerate([dict_divide(params)[i] for i in I]):\n            loc_1_i, loc_2_i, covar_1_i, covar_2_i = self.gen_lightcurve(data, p_sample, jnp.array(Tpred))\n            covar_1 += covar_1_i\n            covar_2 += covar_2_i\n            loc_1_all[k, :] = loc_1_i\n            loc_2_all[k, :] = loc_2_i\n        loc_1 = np.mean(loc_1_all, axis=0)\n        loc_2 = np.mean(loc_2_all, axis=0)\n        covar_1 = covar_1 / num_samples + np.diag(np.var(loc_1_all, axis=0))\n        covar_2 = covar_2 / num_samples + np.diag(np.var(loc_2_all, axis=0))\n\n    err_1, err_2 = np.diag(covar_1) ** 0.5, np.diag(covar_2) ** 0.5\n\n    outs = (lightcurve(Tpred, loc_1, err_1), lightcurve(Tpred, loc_2, err_2))\n\n    return outs\n</code></pre>"},{"location":"models/#litmus.models.stats_model.params_inprior","title":"<code>params_inprior(params) -&gt; bool</code>","text":"<p>Parameters:</p> Name Type Description Default <code>params</code> required <p>Returns:</p> Type Description <code>bool</code> Source code in <code>litmus/models.py</code> <pre><code>def params_inprior(self, params) -&gt; bool:\n    '''\n    :param params:\n    :return:\n    '''\n\n    isgood = {key: True for key in params.keys()}\n    for key in params.keys():\n        if key in self.fixed_params():\n            if np.any(params[key] != self.prior_ranges[key][0]):\n                isgood[key] = False\n            else:\n                isgood[key] = True\n        else:\n            if np.any(\n                    not ((params[key] &gt;= self.prior_ranges[key][0]) and (params[key] &lt; self.prior_ranges[key][1]))):\n                isgood[key] = False\n            else:\n                isgood[key] = True\n    return isgood\n</code></pre>"},{"location":"models/#litmus.models.stats_model.find_seed","title":"<code>find_seed(data, guesses=None, fixed={}) -&gt; (dict, float)</code>","text":"<p>Find a good initial seed. Unless otherwise over-written, while blindly sample the prior and return the best fit.</p> Source code in <code>litmus/models.py</code> <pre><code>def find_seed(self, data, guesses=None, fixed={}) -&gt; (dict, float):\n    '''\n    Find a good initial seed. Unless otherwise over-written, while blindly sample the prior and return the best fit.\n    '''\n\n    if len(fixed.keys()) == len(self.paramnames()): return (fixed, self.log_density(fixed, data))\n\n    if guesses == None: guesses = 50 * 2 ** len(self.free_params())\n\n    samples = self.prior_sample(num_samples=guesses)\n\n    if fixed != {}: samples = dict_extend(samples | fixed)\n\n    ll = self.log_density(samples, data)\n    i = ll.argmax()\n\n    out = dict_divide(samples)[i]\n    return (out, ll.max())\n</code></pre>"},{"location":"models/#litmus.models.GP_simple","title":"<code>GP_simple(prior_ranges=None, **kwargs)</code>","text":"<p>               Bases: <code>stats_model</code></p> <p>An example of how to construct your own stats_model in the simplest form. Requirements are to:     1. Set a default prior range for all parameters used in model_function     2. Define a numpyro generative model model_function You can add / adjust methods as required, but these are the only main steps</p> Source code in <code>litmus/models.py</code> <pre><code>def __init__(self, prior_ranges=None, **kwargs):\n    self._default_prior_ranges = {\n        'lag': _default_config['lag'],\n        'logtau': _default_config['logtau'],\n        'logamp': _default_config['logamp'],\n        'rel_amp': _default_config['rel_amp'],\n        'mean': _default_config['mean'],\n        'rel_mean': _default_config['rel_mean'],\n    }\n    self._protected_keys = ['basekernel']\n    super().__init__(prior_ranges=prior_ranges)\n\n    self.basekernel = kwargs['basekernel'] if 'basekernel' in kwargs.keys() else tinygp.kernels.quasisep.Exp\n</code></pre>"},{"location":"models/#litmus.models.mean_func","title":"<code>mean_func(means, Y) -&gt; ArrayN</code>","text":"<p>DEPRECATED - means are subtracted in the model now Utitlity function to take array of constants and return as gp-friendly functions</p> Source code in <code>litmus/gp_working.py</code> <pre><code>def mean_func(means, Y) -&gt; ArrayN:\n    \"\"\"\n    DEPRECATED - means are subtracted in the model now\n    Utitlity function to take array of constants and return as gp-friendly functions\n\n    \"\"\"\n    t, band = Y\n    return (means[band])\n</code></pre>"},{"location":"models/#litmus.models.build_gp","title":"<code>build_gp(T: ArrayN, Y: ArrayN, diag: ArrayNxN, bands: ArrayN, tau: float, amps: tuple[float, float], means: tuple[float, float], basekernel=tinygp.kernels.quasisep.Exp) -&gt; GaussianProcess</code>","text":"<p>Builds a tinygp two-band kernel for predictions</p> <p>Parameters:</p> Name Type Description Default <code>T</code> <code>ArrayN</code> <p>Time values for the GP</p> required <code>Y</code> <code>ArrayN</code> <p>Y values for the GP (No effect)</p> required <code>diag</code> <code>ArrayNxN</code> <p>Variance matrix (square uncertainties) of the GP</p> required <code>bands</code> <code>ArrayN</code> <p>The bands that the different entries in the time series correspond to</p> required <code>tau</code> <code>float</code> <p>Timescale of the GP</p> required <code>amps</code> <code>tuple[float, float]</code> <p>Amplitudes of the GP</p> required <code>means</code> <code>tuple[float, float]</code> required <code>basekernel</code> <code>Exp</code> Source code in <code>litmus/gp_working.py</code> <pre><code>def build_gp(T: ArrayN, Y: ArrayN, diag: ArrayNxN, bands: ArrayN, tau: float,\n             amps: tuple[float, float], means: tuple[float, float],\n             basekernel=tinygp.kernels.quasisep.Exp) -&gt; GaussianProcess:\n    \"\"\"\n    Builds a tinygp two-band kernel for predictions\n\n    :parameter T: Time values for the GP\n    :parameter Y: Y values for the GP (No effect)\n    :parameter diag: Variance matrix (square uncertainties) of the GP\n    :parameter bands: The bands that the different entries in the time series correspond to\n    :parameter tau: Timescale of the GP\n    :parameter amps: Amplitudes of the GP\n    :parameter means:\n    :parameter basekernel:\n    \"\"\"\n\n    # Create GP kernel with Multiband\n    multi_kernel = Multiband(\n        kernel=basekernel(scale=tau),\n        amplitudes=amps,\n    )\n\n    # Mean functions for offsetting signals\n    meanf = lambda X: mean_func(means, X)\n\n    # Construct GP object and return\n    gp = GaussianProcess(\n        multi_kernel,\n        (T, bands),\n        diag=diag,\n        mean=meanf\n    )\n    return (gp)\n</code></pre>"},{"location":"models/#litmus.models.isiter","title":"<code>isiter(x: any) -&gt; bool</code>","text":"<p>Checks to see if an object is itterable</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter(x: any) -&gt; bool:\n    '''\n    Checks to see if an object is itterable\n    '''\n    if type(x) == dict:\n        return len(x[list(x.keys())[0]]) &gt; 1\n    try:\n        iter(x)\n    except:\n        return (False)\n    else:\n        return (True)\n</code></pre>"},{"location":"models/#litmus.models.isiter_dict","title":"<code>isiter_dict(DICT: dict) -&gt; bool</code>","text":"<p>like isiter but for a dictionary. Checks only the first element in DICT.keys</p> Source code in <code>litmus/_utils.py</code> <pre><code>def isiter_dict(DICT: dict) -&gt; bool:\n    '''\n    like isiter but for a dictionary. Checks only the first element in DICT.keys\n    '''\n\n    key = list(DICT.keys())[0]\n    if isiter(DICT[key]):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"models/#litmus.models.dict_dim","title":"<code>dict_dim(DICT: dict) -&gt; (int, int)</code>","text":"<p>Checks the first element of a dictionary and returns its length</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_dim(DICT: dict) -&gt; (int, int):\n    '''\n    Checks the first element of a dictionary and returns its length\n    '''\n\n    if isiter_dict(DICT):\n        firstkey = list(DICT.keys())[0]\n        return (len(list(DICT.keys())), len(DICT[firstkey]))\n    else:\n        return (len(list(DICT.keys())), 1)\n</code></pre>"},{"location":"models/#litmus.models.dict_pack","title":"<code>dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array</code>","text":"<p>Packs a dictionary into an array format</p> <p>Parameters:</p> Name Type Description Default <code>DICT</code> <code>dict</code> <p>the dict to unpack</p> required <code>keys</code> <p>the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial</p> <code>None</code> <code>recursive</code> <p>whether to recurse into arrays</p> <code>True</code> <code>H</code> <p>Matrix to scale parameters by</p> <code>None</code> <code>d0</code> <p>Value to offset by before packing</p> <code>{}</code> <p>Returns:</p> Type Description <code>array</code> <p>(nkeys x len_array) np.arrayobject  X = H (d-d0)</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_pack(DICT: dict, keys=None, recursive=True, H=None, d0={}) -&gt; np.array:\n    '''\n    Packs a dictionary into an array format\n    :param DICT: the dict to unpack\n    :param keys: the order in which to index the keyed elements. If none, will use DICT.keys(). Can be partial\n    :param recursive: whether to recurse into arrays\n    :param H: Matrix to scale parameters by\n    :param d0: Value to offset by before packing\n    :return: (nkeys x len_array) np.arrayobject\n\n    X = H (d-d0)\n    '''\n\n    nokeys = True if keys is None else 0\n    keys = keys if keys is not None else DICT.keys()\n\n    if d0 is {}: d0 = {key:0 for key in keys}\n\n    for key in keys:\n        if key in DICT.keys() and key not in d0.keys(): d0 |= {key: 0.0}\n\n    if recursive and type(list(DICT.values())[0]) == dict:\n        out = np.array(\n            [dict_pack(DICT[key] - d0[key], keys=keys if not nokeys else None, recursive=recursive) for key in keys])\n    else:\n        if isiter(DICT[list(keys)[0]]):\n            out = np.array([[DICT[key][i] - d0[key] for i in range(dict_dim(DICT)[1])] for key in keys])\n        else:\n            out = np.array([DICT[key] - d0[key] for key in keys])\n\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.dict_unpack","title":"<code>dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array</code>","text":"<p>Unpacks an array into a dict</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Array to unpack</p> required <code>keys</code> <code>[str]</code> <p>keys to unpack with</p> required <p>Returns:</p> Type Description <code>array</code> <p>Hinv(X) + x0</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_unpack(X: np.array, keys: [str], recursive=True, Hinv=None, x0=None) -&gt; np.array:\n    \"\"\"\n    Unpacks an array into a dict\n    :param X: Array to unpack\n    :param keys: keys to unpack with\n    :return:\n\n    Hinv(X) + x0\n    \"\"\"\n    if Hinv is not None: assert Hinv.shape[0] == len(keys), \"Size of H must be equal to number of keys in dict_unpack\"\n\n    if recursive and isiter(X[0]):\n        out = {key: dict_unpack(X[i], keys, recursive) for i, key in enumerate(list(keys))}\n    else:\n        X = X.copy()\n        if Hinv is not None:\n            X = np.dot(Hinv, X)\n        if x0 is not None:\n            X += x0\n        out = {key: X[i] for i, key in enumerate(list(keys))}\n\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.dict_sortby","title":"<code>dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict</code>","text":"<p>Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both. Else, append un-sorted entries to end</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_sortby(A: dict, B: dict, match_only=True) -&gt; dict:\n    \"\"\"\n    Sorts dict A to match keys of dict B. If match_only, returns only for keys common to both.\n    Else, append un-sorted entries to end\n    \"\"\"\n    out = {key: A[key] for key in B if key in A}\n    if not match_only:\n        out |= {key: A[key] for key in A if key not in B}\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.dict_extend","title":"<code>dict_extend(A: dict, B: dict = None) -&gt; dict</code>","text":"<p>Extends all single-length entries of a dict to match the length of a non-singular element</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>dict</code> <p>Dictionary whose elements are to be extended</p> required <code>B</code> <code>dict</code> <p>(optional) the array to extend by, equivalent to dict_extend(A|B)</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_extend(A: dict, B: dict = None) -&gt; dict:\n    '''\n    Extends all single-length entries of a dict to match the length of a non-singular element\n    :param A: Dictionary whose elements are to be extended\n    :param B: (optional) the array to extend by, equivalent to dict_extend(A|B)\n    :return:\n    '''\n\n    out = A.copy()\n    if B is not None: out |= B\n\n    to_extend = [key for key in out if not isiter(out[key])]\n    to_leave = [key for key in out if isiter(out[key])]\n\n    if len(to_extend) == 0: return out\n    if len(to_leave) == 0: return out\n\n    N = len(out[to_leave[0]])\n    for key in to_leave[1:]:\n        assert len(out[key]) == N, \"Tried to dict_extend() a dictionary with inhomogeneous lengths\"\n\n    for key in to_extend:\n        out[key] = np.array([A[key]] * N)\n\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.dict_combine","title":"<code>dict_combine(X: [dict]) -&gt; {str: [float]}</code>","text":"<p>Combines an array, list etc of dictionary into a dictionary of arrays</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_combine(X: [dict]) -&gt; {str: [float]}:\n    '''\n    Combines an array, list etc of dictionary into a dictionary of arrays\n    '''\n\n    N = len(X)\n    keys = X[0].keys()\n\n    out = {key: np.zeros(N) for key in keys}\n    for n in range(N):\n        for key in keys:\n            out[key][n] = X[n][key]\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.dict_divide","title":"<code>dict_divide(X: dict) -&gt; [dict]</code>","text":"<p>Splits dict of arrays into array of dicts</p> Source code in <code>litmus/_utils.py</code> <pre><code>def dict_divide(X: dict) -&gt; [dict]:\n    '''\n    Splits dict of arrays into array of dicts\n    '''\n\n    keys = list(X.keys())\n    N = len(X[keys[0]])\n\n    out = [{key: X[key][i] for key in X} for i in range(N)]\n\n    return (out)\n</code></pre>"},{"location":"models/#litmus.models.pack_function","title":"<code>pack_function(func, packed_keys: [str], fixed_values: dict = {}, invert: bool = False, jit: bool = False, H: np.array = None, d0: dict = {})</code>","text":"<p>Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly Takes a function f(D:dict, arg, kwargs) and returns f(X, D2, args, **kwargs), D2 is all elements of D not listed in 'packed_keys' or fixed_values.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>Function to be unpacked</p> required <code>packed_keys</code> <code>[str]</code> <p>Keys in 'D' to be packed in an array</p> required <code>fixed_values</code> <code>dict</code> <p>Elements of 'D' to be fixed</p> <code>{}</code> <code>invert</code> <code>bool</code> <p>If true, will 'flip' the function upside down</p> <code>False</code> <code>jit</code> <code>bool</code> <p>If true, will 'jit' the function</p> <code>False</code> <code>H</code> <code>array</code> <p>(optional) scaling matrix to reparameterize H with</p> <code>None</code> <code>x0</code> <p>(optional) If given, will center the reparameterized  function at x0</p> required Source code in <code>litmus/_utils.py</code> <pre><code>def pack_function(func, packed_keys: ['str'], fixed_values: dict = {}, invert: bool = False, jit: bool = False,\n                  H: np.array = None, d0: dict = {}):\n    '''\n    Re-arranges a function that takes dict arguments to tak array-like arguments instead, so as to be autograd friendly\n    Takes a function f(D:dict, *arg, **kwargs) and returns f(X, D2, *args, **kwargs), D2 is all elements of D not\n    listed in 'packed_keys' or fixed_values.\n\n    :param func: Function to be unpacked\n    :param packed_keys: Keys in 'D' to be packed in an array\n    :param fixed_values: Elements of 'D' to be fixed\n    :param invert:  If true, will 'flip' the function upside down\n    :param jit: If true, will 'jit' the function\n    :param H: (optional) scaling matrix to reparameterize H with\n    :param x0: (optional) If given, will center the reparameterized  function at x0\n    '''\n\n    if H is not None:\n        assert H.shape[0] == len(packed_keys), \"Scaling matrix H must be same length as packed_keys\"\n    else:\n        H = jnp.eye(len(packed_keys))\n    d0 = {key: 0.0 for key in packed_keys} | d0\n    x0 = dict_pack(d0, packed_keys)\n\n    # --------\n\n    sign = -1 if invert else 1\n\n    # --------\n    def new_func(X, unpacked_params={}, *args, **kwargs):\n        X = jnp.dot(H, X - x0)\n        packed_dict = {key: x for key, x in zip(packed_keys, X)}\n        packed_dict |= unpacked_params\n        packed_dict |= fixed_values\n\n        out = func(packed_dict, *args, **kwargs)\n        return (sign * out)\n\n    # --------\n    if jit: new_func = jax.jit(new_func)\n\n    return (new_func)\n</code></pre>"}]}